{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n"
     ]
    }
   ],
   "source": [
    "defaultVal = [[0.] for idx in range(2*3 + 1)]\n",
    "print(defaultVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data of the subject and returns df with the relevant information\n",
    "def prep_data(path, subject):\n",
    "    data = pd.read_csv(path, sep=' ', header=None)\n",
    "    data.columns = pd.RangeIndex(1, len(data.columns) + 1) \n",
    "    data.drop(3, axis='columns', inplace=True)\n",
    "    data = data.dropna()\n",
    "    data = data[[1,2,22,23,24,28,29,30]]\n",
    "    cols = {1: 'time_step', 2: 'activity_id', 22: 'acc_x', 23: 'acc_y', 24: 'acc_z', 28: 'gyro_x', 29: 'gyro_y', 30: 'gyro_z'}\n",
    "    data = data.rename(columns=cols)\n",
    "    # calculating norm\n",
    "    data['acc_norm'] = np.sqrt(data['acc_x'] ** 2 + data['acc_y'] ** 2 + data['acc_z'] ** 2)\n",
    "    data['gyro_norm'] = np.sqrt(data['gyro_x'] ** 2 + data['gyro_y'] ** 2 + data['gyro_z'] ** 2)\n",
    "    data['User'] = f'{subject}'\n",
    "    print(f'{subject}')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('/Users/momo/Documents/dataset/pamap2+physical+activity+monitoring/Protocol/subject101.dat', sep=' ', header=None)\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n",
      "102\n"
     ]
    }
   ],
   "source": [
    "# Perform preprocess for different subjects\n",
    "# subjects = ['101', '102', '105', '106', '107', '108']\n",
    "subjects = ['101','102']\n",
    "path = '/Users/momo/Documents/dataset/pamap2+physical+activity+monitoring/Protocol'\n",
    "data_list = []\n",
    "for subject in subjects:\n",
    "    data_list.append(prep_data(path + '/subject' + subject + '.dat', subject))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   time_step  activity_id     acc_x    acc_y    acc_z    gyro_x    gyro_y  \\\n",
       " 0       8.38            0  0.238080  9.80003 -1.68896 -0.005065 -0.006781   \n",
       " 1       8.39            0  0.319530  9.61282 -1.49328  0.013685  0.001486   \n",
       " 2       8.40            0  0.235593  9.72421 -1.76621 -0.039923  0.034056   \n",
       " 3       8.41            0  0.388697  9.53572 -1.72410  0.007513 -0.010498   \n",
       " 4       8.42            0  0.315800  9.49908 -1.60914 -0.003822 -0.011217   \n",
       " \n",
       "      gyro_z  acc_norm  gyro_norm User  \n",
       " 0 -0.005663  9.947354   0.010184  101  \n",
       " 1 -0.041522  9.733360   0.043744  101  \n",
       " 2 -0.002113  9.886115   0.052518  101  \n",
       " 3 -0.020684  9.698122   0.024382  101  \n",
       " 4 -0.025975  9.639584   0.028550  101  ,\n",
       "    time_step  activity_id    acc_x    acc_y    acc_z    gyro_x    gyro_y  \\\n",
       " 0       5.64            0  1.94739  9.59644 -3.12873  0.124025  0.112482   \n",
       " 1       5.65            0  1.75120  9.63340 -3.32601  0.132679  0.060829   \n",
       " 2       5.66            0  1.67059  9.70790 -3.48260  0.074772  0.124062   \n",
       " 3       5.67            0  1.66925  9.63234 -3.52110  0.063729  0.136592   \n",
       " 4       5.68            0  1.58969  9.66945 -3.63882  0.008942  0.107000   \n",
       " \n",
       "      gyro_z   acc_norm  gyro_norm User  \n",
       " 0 -0.044947  10.279734   0.173363  102  \n",
       " 1 -0.044168  10.340766   0.152495  102  \n",
       " 2 -0.053608  10.448095   0.154454  102  \n",
       " 3  0.004851  10.390694   0.150806  102  \n",
       " 4  0.003266  10.453056   0.107423  102  )"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[0].head(),data_list[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine to one df\n",
    "for d in range(len(data_list)):\n",
    "  if d==0:\n",
    "    df = data_list[0]\n",
    "  else:\n",
    "    df = pd.concat([df, data_list[d]], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df, cols): #list of columns\n",
    "    df_t=(df[cols]-df[cols].mean())/df[cols].std() #均值为0，方差为1的分布\n",
    "    df_norm = df.copy()\n",
    "    df_norm[cols] = df_t\n",
    "\n",
    "    return df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm = normalize(df, ['acc_norm', 'gyro_norm'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(df, cols, sigma=0.1):\n",
    "    noise = np.random.normal(0, sigma, df[cols].shape)\n",
    "    new_signal = df[cols] + noise\n",
    "    df_noise = df.copy()\n",
    "    df_noise[cols] = new_signal\n",
    "\n",
    "    return df_noise\n",
    "\n",
    "def augment(df, cols, num_of_inst):\n",
    "    '''\n",
    "    df should be inserted normalized\n",
    "    num_of_inst = num of instances to create from each instance\n",
    "    '''\n",
    "    aug_df = df.copy()\n",
    "    for i in range(num_of_inst):\n",
    "        np.random.seed(i)\n",
    "        nois_data = add_noise(df, cols)\n",
    "        nois_data['User'] = nois_data['User'] + f'{i}'\n",
    "        aug_df= pd.concat([aug_df, nois_data], axis=0, ignore_index=True)\n",
    "\n",
    "    return aug_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aug = augment(data_norm, ['acc_norm', 'gyro_norm'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_step</th>\n",
       "      <th>activity_id</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gyro_x</th>\n",
       "      <th>gyro_y</th>\n",
       "      <th>gyro_z</th>\n",
       "      <th>acc_norm</th>\n",
       "      <th>gyro_norm</th>\n",
       "      <th>User</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.238080</td>\n",
       "      <td>9.80003</td>\n",
       "      <td>-1.68896</td>\n",
       "      <td>-0.005065</td>\n",
       "      <td>-0.006781</td>\n",
       "      <td>-0.005663</td>\n",
       "      <td>-0.066101</td>\n",
       "      <td>-0.818660</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.319530</td>\n",
       "      <td>9.61282</td>\n",
       "      <td>-1.49328</td>\n",
       "      <td>0.013685</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>-0.041522</td>\n",
       "      <td>-0.128133</td>\n",
       "      <td>-0.764882</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.235593</td>\n",
       "      <td>9.72421</td>\n",
       "      <td>-1.76621</td>\n",
       "      <td>-0.039923</td>\n",
       "      <td>0.034056</td>\n",
       "      <td>-0.002113</td>\n",
       "      <td>-0.083853</td>\n",
       "      <td>-0.750823</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.41</td>\n",
       "      <td>0</td>\n",
       "      <td>0.388697</td>\n",
       "      <td>9.53572</td>\n",
       "      <td>-1.72410</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>-0.010498</td>\n",
       "      <td>-0.020684</td>\n",
       "      <td>-0.138347</td>\n",
       "      <td>-0.795908</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.42</td>\n",
       "      <td>0</td>\n",
       "      <td>0.315800</td>\n",
       "      <td>9.49908</td>\n",
       "      <td>-1.60914</td>\n",
       "      <td>-0.003822</td>\n",
       "      <td>-0.011217</td>\n",
       "      <td>-0.025975</td>\n",
       "      <td>-0.155316</td>\n",
       "      <td>-0.789230</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_step  activity_id     acc_x    acc_y    acc_z    gyro_x    gyro_y  \\\n",
       "0       8.38            0  0.238080  9.80003 -1.68896 -0.005065 -0.006781   \n",
       "1       8.39            0  0.319530  9.61282 -1.49328  0.013685  0.001486   \n",
       "2       8.40            0  0.235593  9.72421 -1.76621 -0.039923  0.034056   \n",
       "3       8.41            0  0.388697  9.53572 -1.72410  0.007513 -0.010498   \n",
       "4       8.42            0  0.315800  9.49908 -1.60914 -0.003822 -0.011217   \n",
       "\n",
       "     gyro_z  acc_norm  gyro_norm User  \n",
       "0 -0.005663 -0.066101  -0.818660  101  \n",
       "1 -0.041522 -0.128133  -0.764882  101  \n",
       "2 -0.002113 -0.083853  -0.750823  101  \n",
       "3 -0.020684 -0.138347  -0.795908  101  \n",
       "4 -0.025975 -0.155316  -0.789230  101  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_aug.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['101', '1010', '102', '1020'], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa = data_aug\n",
    "np.unique(aaa['activity_id'])\n",
    "np.unique(aaa['User'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 5),\n",
       " Empty DataFrame\n",
       " Columns: [activity, timstep, user, acc_spec, gyro_spec]\n",
       " Index: [])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_data = data_aug\n",
    "unique_actions = np.unique(initial_data['activity_id'])\n",
    "unique_users = np.unique(initial_data['User'])\n",
    "dff = pd.DataFrame(columns=['activity','timstep', 'user','acc_spec','gyro_spec'])\n",
    "print(dff.shape)\n",
    "dff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7 12 13 16 17 24]\n"
     ]
    }
   ],
   "source": [
    "print(unique_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action:  1\n",
      "user:  101\n",
      "(27179, 11) 6\n"
     ]
    }
   ],
   "source": [
    "# path = '/content/drive/MyDrive/Advanced ML final project/sepc_6_users'\n",
    "for action in [1]:\n",
    "    print('action: ', action)\n",
    "    for user in ['101']:\n",
    "        print('user: ', user)\n",
    "        act_user_temp = initial_data[(initial_data['activity_id']==action) & (initial_data['User']==user)]\n",
    "        NFFT = 25\n",
    "        noverlap = int(0.25 * NFFT)\n",
    "        print(act_user_temp.shape, noverlap)\n",
    "        fig = plt.figure(frameon=False)\n",
    "        sr = 100\n",
    "        timestep = 0\n",
    "        for row in range(0, act_user_temp.shape[0], 150): # overlap of the data is 50%. not the hyperparameter of FFT.\n",
    "            timestep += 1\n",
    "            spec_acc, freqenciesFound_x, time, imageAxis_x = plt.specgram(act_user_temp['acc_norm'][row:row + 200], Fs=100, NFFT=NFFT, noverlap=noverlap, window=np.hamming(NFFT),cmap='viridis')\n",
    "            spec_gyro, freqenciesFound_x, time, imageAxis_x = plt.specgram(act_user_temp['gyro_norm'][row:row + 200], Fs=100, NFFT=NFFT, noverlap=noverlap, window=np.hamming(NFFT),cmap='viridis')\n",
    "            instance = pd.DataFrame({'activity':action, 'timstep':timestep, 'user':user, 'acc_spec':[spec_acc], 'gyro_spec':[spec_gyro]})\n",
    "            dff = dff.append(instance, ignore_index=True) # label, timestep, user, f*t (spectrogram), f*t (spectrogram)\n",
    "        plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dff.to_pickle(\"path/labeled_data_6_users_2_sec.pkl\")\n",
    "# df = pd.read_pickle(\"path/labeled_data_6_users_2_sec.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 filtering targeted activities and making the labels sequencials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df['activity'].isin([1,2,3,4,5,6,7,12,13,16,17])]\n",
    "# df['activity'].loc[(df['activity']==12)] = 8\n",
    "# df['activity'].loc[(df['activity']==13)] = 9\n",
    "# df['activity'].loc[(df['activity']==16)] = 10\n",
    "# df['activity'].loc[(df['activity']==17)] = 0\n",
    "# df[df['activity'] == 10].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEPCTURAL_SAMPLES = 10\n",
    "FEATURE_DIM = SEPCTURAL_SAMPLES*6*2\n",
    "CONV_LEN = 3\n",
    "CONV_LEN_INTE = 3#4\n",
    "CONV_LEN_LAST = 3#5\n",
    "CONV_NUM = 64\n",
    "CONV_MERGE_LEN = 8\n",
    "CONV_MERGE_LEN2 = 6\n",
    "CONV_MERGE_LEN3 = 4\n",
    "CONV_NUM2 = 64\n",
    "INTER_DIM = 120\n",
    "OUT_DIM = 6#len(idDict)\n",
    "WIDE = 20\n",
    "CONV_KEEP_PROB = 0.8\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "TOTAL_ITER_NUM = 30000\n",
    "\n",
    "select = 'a'\n",
    "\n",
    "metaDict = {'a':[119080, 1193], 'b':[116870, 1413], 'c':[116020, 1477]}\n",
    "TRAIN_SIZE = metaDict[select][0]\n",
    "EVAL_DATA_SIZE = metaDict[select][1]\n",
    "EVAL_ITER_NUM = int(math.ceil(EVAL_DATA_SIZE / BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNormLayer(nn.Module):\n",
    "    def __init__(self, num_features, eps=1e-5, momentum=0.1):\n",
    "        super(BatchNormLayer, self).__init__()\n",
    "        self.bn = nn.BatchNorm1d(num_features, eps=eps, momentum=momentum)\n",
    "\n",
    "    def forward(self, inputs, phase_train):\n",
    "        if phase_train:\n",
    "            return self.bn(inputs)\n",
    "        else:\n",
    "            return self.bn(inputs)\n",
    "\n",
    "# Usage:\n",
    "# phase_train = True for training, and False for evaluation\n",
    "# Example usage: batch_norm_layer = BatchNormLayer(num_features=32, eps=1e-5, momentum=0.1)\n",
    "#                output = batch_norm_layer(input_tensor, phase_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensor_local_feature_layer(inputs, name, train):\n",
    "    # CONV_NUM is 64\n",
    "    conv1 = nn.Conv2d(inputs.size(1), CONV_NUM, kernel_size=(1, 2*3*CONV_LEN), stride=(1, 2*3), padding=0)\n",
    "    conv1 = nn.BatchNorm2d(CONV_NUM)\n",
    "    conv1_shape = conv1(inputs).size()\n",
    "    print(\"conv1 \", conv1_shape)\n",
    "    conv1 = nn.ReLU(inplace=True)\n",
    "    conv1 = nn.Dropout2d(p=1-CONV_KEEP_PROB)(conv1(inputs))\n",
    "\n",
    "    # CONV_LEN_INTE is 3\n",
    "    conv2 = nn.Conv2d(CONV_NUM, CONV_NUM, kernel_size=(1, CONV_LEN_INTE), stride=(1, 1), padding=0)\n",
    "    conv2 = nn.BatchNorm2d(CONV_NUM)\n",
    "    conv2_shape = conv2(conv1).size()\n",
    "    print(\"conv2 \", conv2_shape)\n",
    "    conv2 = nn.ReLU(inplace=True)\n",
    "    conv2 = nn.Dropout2d(p=1-CONV_KEEP_PROB)(conv2(conv1))\n",
    "\n",
    "    # CONV_LEN_LAST is 3\n",
    "    conv3 = nn.Conv2d(CONV_NUM, CONV_NUM, kernel_size=(1, CONV_LEN_LAST), stride=(1, 1), padding=0)\n",
    "    conv3 = nn.BatchNorm2d(CONV_NUM)\n",
    "    conv3_shape = conv3(conv2).size()\n",
    "    print(\"conv3 \", conv3_shape)\n",
    "\n",
    "    conv_out = conv3.view(conv3_shape[0], conv3_shape[1], 1, conv3_shape[2], conv3_shape[3])\n",
    "    return conv_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_acc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_acc, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, (1,3), padding='same')\n",
    "        self.conv2 = nn.Conv2d(32, 32, (1,3), padding='same')\n",
    "        self.conv3 = nn.Conv2d(32, 64, (1,3), padding='same')\n",
    "        self.conv4 = nn.Conv2d(64, 64, (1,3), padding='same')\n",
    "        self.fc = nn.Linear(2048, 128)\n",
    "        torch.nn.init.xavier_normal(self.fc.weight)\n",
    "        torch.nn.init.xavier_normal(self.conv1.weight)\n",
    "        torch.nn.init.xavier_normal(self.conv2.weight)\n",
    "        torch.nn.init.xavier_normal(self.conv3.weight)\n",
    "        torch.nn.init.xavier_normal(self.conv4.weight)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print('x.shape 1: ', x.shape)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        # print('x.shape 2: ', x.shape)\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), (1,2)))\n",
    "        # print('x.shape 3: ', x.shape)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        # print('x.shape 4: ', x.shape)\n",
    "        x = F.relu(F.max_pool2d(self.conv4(x), (1,2)))\n",
    "        # print('x.shape 5: ', x.shape)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        # print('x.shape 6: ', x.shape)\n",
    "        x = self.fc(x)\n",
    "        # print('x.shape 7: ', x.shape)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs= np.ones(120).reshape([2, 3, 4, 5])\n",
    "inputs = torch.from_numpy(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_fusion_1(inputs): # Attention-fusion Subnet\n",
    "    \"\"\"inputs, shape: [batch, time_step, input_mode, feature_dim]\"\"\"\n",
    "    d = inputs.shape[-1]\n",
    "    w = torch.randn(d, requires_grad=True, dtype=torch.double) * 0.1 # weights\n",
    "    b = torch.randn(1, requires_grad=True, dtype=torch.double) \n",
    "\n",
    "    activation = torch.tanh(torch.matmul(inputs, w) + b)  # b * t * i\n",
    "    alphas = F.softmax(activation, dim=-1)  # b * t * i\n",
    "    print(\"alphas \", str(alphas.shape))\n",
    "\n",
    "    output = torch.sum(inputs * alphas.unsqueeze(-1), dim=2)\n",
    "    print(output.shape) #shape: [batch, time_step, 1, feature_dim]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(inputs, attention_size, time_major=False, return_alphas=False):\n",
    "    if isinstance(inputs, tuple):\n",
    "        # In case of Bi-RNN, concatenate the forward and the backward RNN outputs.\n",
    "        inputs = torch.cat(inputs, 2)\n",
    "\n",
    "    if time_major:\n",
    "        # (T,B,D) => (B,T,D)\n",
    "        inputs = inputs.transpose(0, 1)\n",
    "\n",
    "    hidden_size = inputs.size(2)  # D value - hidden size of the RNN layer\n",
    "\n",
    "    # Trainable parameters\n",
    "    w_omega = nn.Parameter(torch.randn(hidden_size, attention_size) * 0.1)\n",
    "    b_omega = nn.Parameter(torch.randn(attention_size) * 0.1)\n",
    "    u_omega = nn.Parameter(torch.randn(attention_size) * 0.1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        w_omega.requiresGrad = True\n",
    "        b_omega.requiresGrad = True\n",
    "        u_omega.requiresGrad = True\n",
    "\n",
    "    with torch.name_scope('v'):\n",
    "        # Applying fully connected layer with non-linear activation to each of the B*T timestamps;\n",
    "        # the shape of `v` is (B,T,D)*(D,A)=(B,T,A), where A=attention_size\n",
    "        v = torch.tanh(torch.matmul(inputs, w_omega) + b_omega)\n",
    "\n",
    "    # For each of the timestamps, its vector of size A from `v` is reduced with the `u` vector\n",
    "    vu = torch.matmul(v, u_omega).squeeze(-1)  # (B,T) shape\n",
    "    alphas = F.softmax(vu, dim=1)   # (B,T) shape\n",
    "\n",
    "    # Output of (Bi-)RNN is reduced with the attention vector; the result has (B,D) shape\n",
    "    output = torch.sum(inputs * alphas.unsqueeze(-1), dim=1)\n",
    "\n",
    "    if not return_alphas:\n",
    "        return output\n",
    "    else:\n",
    "        return output, alphas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_attention(inputs, name):\n",
    "    \"\"\"\n",
    "    :param inputs: input tensor (B, T, 3, dim)\n",
    "    :param name: scope name\n",
    "    :return: final_output (B, T, dim)\n",
    "    \"\"\"\n",
    "    t = inputs.size(1)\n",
    "    share_param = True\n",
    "    hidden_size = inputs.size(-1)  # D value - hidden size of the RNN layer\n",
    "\n",
    "    if share_param:\n",
    "        scope_name = 'self_attn'\n",
    "    else:\n",
    "        scope_name = 'self_attn' + name\n",
    "\n",
    "    inputs = inputs.transpose(1, 0)  # (T, B, 3, dim)\n",
    "\n",
    "    outputs = []\n",
    "    for x in range(t):\n",
    "        t_x = inputs[x]  # (B, 3, dim)\n",
    "\n",
    "        den = True\n",
    "        if den:\n",
    "            x_proj = nn.Linear(hidden_size, hidden_size)(t_x)\n",
    "            x_proj = torch.tanh(x_proj)\n",
    "        else:\n",
    "            x_proj = t_x\n",
    "\n",
    "        u_w = nn.Parameter(torch.randn(hidden_size, 1) * 0.01, requires_grad=True)\n",
    "        x = torch.matmul(x_proj, u_w)  # (B, 3, 1)\n",
    "        alphas = F.softmax(x, dim=1)  # (B, 3, 1)\n",
    "\n",
    "        output = torch.matmul(t_x.transpose(1, 2), alphas)  # (B, dim, 1)\n",
    "        output = output.squeeze(-1)  # (B, dim)\n",
    "        outputs.append(output)\n",
    "\n",
    "    final_output = torch.stack(outputs, dim=1)  # (B, T, dim)\n",
    "\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepSense(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, train=True, name='deepSense'):\n",
    "        super(DeepSense, self).__init__()\n",
    "        self.train = train\n",
    "        self.name = name\n",
    "        self.used = None\n",
    "        self.avgNum = None\n",
    "\n",
    "        # Define other layers here if needed\n",
    "\n",
    "        self.gru_cell1 = nn.GRUCell(input_size, hidden_size)\n",
    "        if train:\n",
    "            self.gru_cell1 = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.gru_cell2 = nn.GRUCell(hidden_size, hidden_size)\n",
    "        if train:\n",
    "            self.gru_cell2 = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.cell = nn.RNNCellBase([self.gru_cell1, self.gru_cell2])\n",
    "        self.init_state = torch.zeros(2, BATCH_SIZE, hidden_size, dtype=torch.float32)\n",
    "\n",
    "        self.AZ = 80\n",
    "        self.attention_out = None\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        used = torch.sign(torch.max(torch.abs(inputs), dim=2)[0])  # (BATCH_SIZE, WIDE)\n",
    "        self.used = used\n",
    "        length = torch.sum(used, dim=1)  # (BATCH_SIZE)\n",
    "        length = length.type(torch.int64)\n",
    "\n",
    "        mask = torch.sign(torch.max(torch.abs(inputs), dim=2, keepdim=True)[0])\n",
    "        mask = mask.repeat(1, 1, INTER_DIM)  # (BATCH_SIZE, WIDE, INTER_DIM)\n",
    "        avgNum = torch.sum(mask, dim=1)  # (BATCH_SIZE, INTER_DIM)\n",
    "        self.avgNum = avgNum\n",
    "\n",
    "        sensor_inputs = inputs.unsqueeze(3)  # (BATCH_SIZE, WIDE, FEATURE_DIM, CHANNEL=1)\n",
    "        acc_inputs, gyro_inputs = torch.split(sensor_inputs, split_size_or_sections=input_size // 2, dim=2)\n",
    "\n",
    "        acc_conv_out = self.sensor_local_feature_layer(acc_inputs, \"acc\", train=self.train)\n",
    "        gyro_conv_out = self.sensor_local_feature_layer(gyro_inputs, \"gyro\", train=self.train)\n",
    "\n",
    "        sensor_conv_in = torch.cat([acc_conv_out, gyro_conv_out], dim=2)\n",
    "        sensor_conv3 = sensor_conv_in\n",
    "\n",
    "        attention_input = sensor_conv3.view(sensor_conv3.size(0), sensor_conv3.size(1), sensor_conv3.size(2),\n",
    "                                            sensor_conv3.size(3) * sensor_conv3.size(4))\n",
    "        sensor_conv_out = self.attention_fusion_1(attention_input)\n",
    "\n",
    "        self.init_state = torch.zeros(2, inputs.size(0), self.cell.hidden_size, dtype=torch.float32)\n",
    "        cell_output = []\n",
    "        h_t = self.init_state\n",
    "\n",
    "        for t in range(inputs.size(1)):\n",
    "            h_t = self.cell(inputs[:, t], h_t)\n",
    "            cell_output.append(h_t)\n",
    "\n",
    "        cell_output = torch.stack(cell_output, dim=1)  # (BATCH_SIZE, WIDE, INTER_DIM)\n",
    "\n",
    "        attention_out = self.attention(cell_output, attention_size=self.AZ)\n",
    "        self.attention_out = attention_out\n",
    "\n",
    "        avg_cell_out = attention_out\n",
    "\n",
    "        # Define other operations here if needed\n",
    "\n",
    "        # Assuming fully connected layer for logits\n",
    "        logits = self.fully_connected_layer(avg_cell_out)\n",
    "\n",
    "        return logits\n",
    "\n",
    "\n",
    "# Usage:\n",
    "# Create an instance of DeepSense with appropriate input_size, hidden_size, output_size, and train (True for training, False for evaluation)\n",
    "# deep_sense_model = DeepSense(input_size=..., hidden_size=..., output_size=..., train=...)\n",
    "# logits = deep_sense_model(input_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the DeepSense model with training mode\n",
    "deep_sense_model = DeepSense(input_size=..., hidden_size=..., output_size=..., train=True)\n",
    "\n",
    "# Forward pass to get model\n",
    "model = deep_sense_model(batch_feature)\n",
    "\n",
    "# Calculate the predictions\n",
    "_, predict = torch.max(model, dim=1)\n",
    "\n",
    "# Calculate the cross-entropy loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "batchLoss = criterion(model, batch_label)\n",
    "loss = torch.mean(batchLoss)\n",
    "\n",
    "# Create an instance of the DeepSense model with evaluation mode (reuse=True)\n",
    "deep_sense_model_eval = DeepSense(input_size=..., hidden_size=..., output_size=..., train=False, reuse=True)\n",
    "\n",
    "# Forward pass to get model for evaluation\n",
    "model_eval = deep_sense_model_eval(batch_eval_feature)\n",
    "\n",
    "# Calculate the predictions for evaluation\n",
    "_, predict_eval = torch.max(model_eval, dim=1)\n",
    "\n",
    "# Calculate the cross-entropy loss for evaluation\n",
    "loss_eval = torch.mean(criterion(model_eval, batch_eval_label))\n",
    "\n",
    "# Get the trainable parameters of the model\n",
    "t_params = deep_sense_model.parameters()\n",
    "\n",
    "# Calculate the L2 regularization term\n",
    "regularizers = torch.tensor(0., dtype=torch.float32)\n",
    "for param in t_params:\n",
    "    regularizers += torch.sum(param * param)  # L2 loss\n",
    "loss += 5e-4 * regularizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the DeepSense model with training mode\n",
    "deep_sense_model = DeepSense(input_size=..., hidden_size=..., output_size=..., train=True)\n",
    "\n",
    "# Initialize model parameters\n",
    "deep_sense_model.apply(weights_init)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "deep_sense_model.to(device)\n",
    "\n",
    "# Assuming you have defined the data loaders for training and evaluation\n",
    "train_loader = ...\n",
    "eval_loader = ...\n",
    "\n",
    "best = -0.1\n",
    "for iteration in range(TOTAL_ITER_NUM):\n",
    "    deep_sense_model.train()  # Set the model to training mode\n",
    "\n",
    "    for batch_feature, batch_label in train_loader:\n",
    "        batch_feature = batch_feature.to(device)\n",
    "        batch_label = batch_label.to(device)\n",
    "\n",
    "        # Forward pass and calculate loss\n",
    "        logits = deep_sense_model(batch_feature)\n",
    "        loss = criterion(logits, batch_label)\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        discOptimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        discOptimizer.step()\n",
    "\n",
    "        # Assuming you have implemented a function to calculate accuracy\n",
    "        accuracy = calculate_accuracy(logits, batch_label)\n",
    "\n",
    "        # Plot training statistics (Note: Implement a similar plot function)\n",
    "        plot.plot('train cross entropy', loss.item())\n",
    "        plot.plot('train accuracy', accuracy)\n",
    "\n",
    "    if iteration % 50 == 49:\n",
    "        deep_sense_model.eval()  # Set the model to evaluation mode\n",
    "        dev_accuracy = []\n",
    "        dev_cross_entropy = []\n",
    "        with torch.no_grad():\n",
    "            for batch_eval_feature, batch_eval_label in eval_loader:\n",
    "                batch_eval_feature = batch_eval_feature.to(device)\n",
    "                batch_eval_label = batch_eval_label.to(device)\n",
    "\n",
    "                # Forward pass for evaluation\n",
    "                logits_eval = deep_sense_model(batch_eval_feature)\n",
    "                eval_loss = criterion(logits_eval, batch_eval_label)\n",
    "\n",
    "                # Calculate accuracy for evaluation\n",
    "                eval_accuracy = calculate_accuracy(logits_eval, batch_eval_label)\n",
    "\n",
    "                dev_accuracy.append(eval_accuracy)\n",
    "                dev_cross_entropy.append(eval_loss.item())\n",
    "\n",
    "        mean_dev_accuracy = torch.mean(torch.tensor(dev_accuracy))\n",
    "        best = max(best, mean_dev_accuracy)\n",
    "        plot.plot('dev accuracy', mean_dev_accuracy.item())\n",
    "        plot.plot('dev cross entropy', torch.mean(torch.tensor(dev_cross_entropy)).item())\n",
    "\n",
    "    if (iteration < 5) or (iteration % 50 == 49):\n",
    "        plot.flush()\n",
    "\n",
    "    plot.tick()\n",
    "\n",
    "print(\"best score \" + str(best))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
