{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import math\n",
    "import pickle\n",
    "from plot import *\n",
    "from utils import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, RandomSampler, SequentialSampler, random_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from scipy.signal import stft\n",
    "from scipy.fft import fft, fftfreq,rfft, rfftfreq\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "################  Parameters  ################\n",
    "\n",
    "SEPCTURAL_SAMPLES = 13 # 10 in original code\n",
    "FEATURE_DIM = SEPCTURAL_SAMPLES*6*2\n",
    "CONV_K = [3,3,3] #[3,4,5]\n",
    "CONV_C = [32,32,64] # Channels\n",
    "GRU_H = [120,120] # rnn hidden size\n",
    "AT = 80\n",
    "OUT_DIM = 6 # number of activities\n",
    "WIDE = 20 # window size\n",
    "CONV_KEEP_PROB = 0.8 # dropout\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 3000\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "PATH = './'\n",
    "\n",
    "# CONV_MERGE_LEN = 8\n",
    "# CONV_MERGE_LEN2 = 6\n",
    "# CONV_MERGE_LEN3 = 4\n",
    "# CONV_NUM2 = 64\n",
    "\n",
    "# select = 'a'\n",
    "# metaDict = {'a':[119080, 1193], 'b':[116870, 1413], 'c':[116020, 1477]}\n",
    "# TRAIN_SIZE = metaDict[select][0]\n",
    "# EVAL_DATA_SIZE = metaDict[select][1]\n",
    "# EVAL_ITER_NUM = int(math.ceil(EVAL_DATA_SIZE / BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAMAP Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.38</td>\n",
       "      <td>0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.37223</td>\n",
       "      <td>8.60074</td>\n",
       "      <td>3.51048</td>\n",
       "      <td>2.43954</td>\n",
       "      <td>8.76165</td>\n",
       "      <td>3.35465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>0.009250</td>\n",
       "      <td>-0.017580</td>\n",
       "      <td>-61.1888</td>\n",
       "      <td>-38.9599</td>\n",
       "      <td>-58.1438</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.39</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.18837</td>\n",
       "      <td>8.56560</td>\n",
       "      <td>3.66179</td>\n",
       "      <td>2.39494</td>\n",
       "      <td>8.55081</td>\n",
       "      <td>3.64207</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006577</td>\n",
       "      <td>-0.004638</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>-59.8479</td>\n",
       "      <td>-38.8919</td>\n",
       "      <td>-58.5253</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.40</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.37357</td>\n",
       "      <td>8.60107</td>\n",
       "      <td>3.54898</td>\n",
       "      <td>2.30514</td>\n",
       "      <td>8.53644</td>\n",
       "      <td>3.73280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003014</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.022495</td>\n",
       "      <td>-60.7361</td>\n",
       "      <td>-39.4138</td>\n",
       "      <td>-58.3999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.41</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.07473</td>\n",
       "      <td>8.52853</td>\n",
       "      <td>3.66021</td>\n",
       "      <td>2.33528</td>\n",
       "      <td>8.53622</td>\n",
       "      <td>3.73277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>-0.020301</td>\n",
       "      <td>0.011275</td>\n",
       "      <td>-60.4091</td>\n",
       "      <td>-38.7635</td>\n",
       "      <td>-58.3956</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.42</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.22936</td>\n",
       "      <td>8.83122</td>\n",
       "      <td>3.70000</td>\n",
       "      <td>2.23055</td>\n",
       "      <td>8.59741</td>\n",
       "      <td>3.76295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012698</td>\n",
       "      <td>-0.014303</td>\n",
       "      <td>-0.002823</td>\n",
       "      <td>-61.5199</td>\n",
       "      <td>-39.3879</td>\n",
       "      <td>-58.2694</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1      2     3        4        5        6        7        8   \\\n",
       "0  8.38   0  104.0  30.0  2.37223  8.60074  3.51048  2.43954  8.76165   \n",
       "1  8.39   0    NaN  30.0  2.18837  8.56560  3.66179  2.39494  8.55081   \n",
       "2  8.40   0    NaN  30.0  2.37357  8.60107  3.54898  2.30514  8.53644   \n",
       "3  8.41   0    NaN  30.0  2.07473  8.52853  3.66021  2.33528  8.53622   \n",
       "4  8.42   0    NaN  30.0  2.22936  8.83122  3.70000  2.23055  8.59741   \n",
       "\n",
       "        9   ...        44        45        46       47       48       49   50  \\\n",
       "0  3.35465  ...  0.008300  0.009250 -0.017580 -61.1888 -38.9599 -58.1438  1.0   \n",
       "1  3.64207  ... -0.006577 -0.004638  0.000368 -59.8479 -38.8919 -58.5253  1.0   \n",
       "2  3.73280  ...  0.003014  0.000148  0.022495 -60.7361 -39.4138 -58.3999  1.0   \n",
       "3  3.73277  ...  0.003175 -0.020301  0.011275 -60.4091 -38.7635 -58.3956  1.0   \n",
       "4  3.76295  ...  0.012698 -0.014303 -0.002823 -61.5199 -39.3879 -58.2694  1.0   \n",
       "\n",
       "    51   52   53  \n",
       "0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/Users/momo/Documents/dataset/pamap2+physical+activity+monitoring/Protocol/subject101.dat', sep=' ', header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data of the subject and returns df with the relevant information\n",
    "def prep_data(path, subject):\n",
    "    data = pd.read_csv(path, sep=' ', header=None)\n",
    "    data.columns = pd.RangeIndex(1, len(data.columns) + 1) \n",
    "    data.drop(3, axis='columns', inplace=True)\n",
    "    data = data.dropna()\n",
    "    data = data[[1,2,22,23,24,28,29,30]]\n",
    "    cols = {1: 'time_step', 2: 'activity_id', 22: 'acc_x', 23: 'acc_y', 24: 'acc_z', 28: 'gyro_x', 29: 'gyro_y', 30: 'gyro_z'}\n",
    "    data = data.rename(columns=cols)\n",
    "    # calculating norm\n",
    "    data['acc_norm'] = np.sqrt(data['acc_x'] ** 2 + data['acc_y'] ** 2 + data['acc_z'] ** 2)\n",
    "    data['gyro_norm'] = np.sqrt(data['gyro_x'] ** 2 + data['gyro_y'] ** 2 + data['gyro_z'] ** 2)\n",
    "    data['User'] = f'{subject}'\n",
    "    print(f'{subject}')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    }
   ],
   "source": [
    "# Perform preprocess for different subjects\n",
    "# subjects = ['101', '102', '105', '106', '107', '108']\n",
    "subjects = ['101']\n",
    "path = '/Users/momo/Documents/dataset/pamap2+physical+activity+monitoring/Protocol'\n",
    "data_list = []\n",
    "for subject in subjects:\n",
    "    data_list.append(prep_data(path + '/subject' + subject + '.dat', subject))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_step</th>\n",
       "      <th>activity_id</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gyro_x</th>\n",
       "      <th>gyro_y</th>\n",
       "      <th>gyro_z</th>\n",
       "      <th>acc_norm</th>\n",
       "      <th>gyro_norm</th>\n",
       "      <th>User</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.238080</td>\n",
       "      <td>9.80003</td>\n",
       "      <td>-1.68896</td>\n",
       "      <td>-0.005065</td>\n",
       "      <td>-0.006781</td>\n",
       "      <td>-0.005663</td>\n",
       "      <td>9.947354</td>\n",
       "      <td>0.010184</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.319530</td>\n",
       "      <td>9.61282</td>\n",
       "      <td>-1.49328</td>\n",
       "      <td>0.013685</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>-0.041522</td>\n",
       "      <td>9.733360</td>\n",
       "      <td>0.043744</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.235593</td>\n",
       "      <td>9.72421</td>\n",
       "      <td>-1.76621</td>\n",
       "      <td>-0.039923</td>\n",
       "      <td>0.034056</td>\n",
       "      <td>-0.002113</td>\n",
       "      <td>9.886115</td>\n",
       "      <td>0.052518</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.41</td>\n",
       "      <td>0</td>\n",
       "      <td>0.388697</td>\n",
       "      <td>9.53572</td>\n",
       "      <td>-1.72410</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>-0.010498</td>\n",
       "      <td>-0.020684</td>\n",
       "      <td>9.698122</td>\n",
       "      <td>0.024382</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.42</td>\n",
       "      <td>0</td>\n",
       "      <td>0.315800</td>\n",
       "      <td>9.49908</td>\n",
       "      <td>-1.60914</td>\n",
       "      <td>-0.003822</td>\n",
       "      <td>-0.011217</td>\n",
       "      <td>-0.025975</td>\n",
       "      <td>9.639584</td>\n",
       "      <td>0.028550</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_step  activity_id     acc_x    acc_y    acc_z    gyro_x    gyro_y  \\\n",
       "0       8.38            0  0.238080  9.80003 -1.68896 -0.005065 -0.006781   \n",
       "1       8.39            0  0.319530  9.61282 -1.49328  0.013685  0.001486   \n",
       "2       8.40            0  0.235593  9.72421 -1.76621 -0.039923  0.034056   \n",
       "3       8.41            0  0.388697  9.53572 -1.72410  0.007513 -0.010498   \n",
       "4       8.42            0  0.315800  9.49908 -1.60914 -0.003822 -0.011217   \n",
       "\n",
       "     gyro_z  acc_norm  gyro_norm User  \n",
       "0 -0.005663  9.947354   0.010184  101  \n",
       "1 -0.041522  9.733360   0.043744  101  \n",
       "2 -0.002113  9.886115   0.052518  101  \n",
       "3 -0.020684  9.698122   0.024382  101  \n",
       "4 -0.025975  9.639584   0.028550  101  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_step</th>\n",
       "      <th>activity_id</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gyro_x</th>\n",
       "      <th>gyro_y</th>\n",
       "      <th>gyro_z</th>\n",
       "      <th>acc_norm</th>\n",
       "      <th>gyro_norm</th>\n",
       "      <th>User</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.238080</td>\n",
       "      <td>9.80003</td>\n",
       "      <td>-1.68896</td>\n",
       "      <td>-0.005065</td>\n",
       "      <td>-0.006781</td>\n",
       "      <td>-0.005663</td>\n",
       "      <td>9.947354</td>\n",
       "      <td>0.010184</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.319530</td>\n",
       "      <td>9.61282</td>\n",
       "      <td>-1.49328</td>\n",
       "      <td>0.013685</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>-0.041522</td>\n",
       "      <td>9.733360</td>\n",
       "      <td>0.043744</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.235593</td>\n",
       "      <td>9.72421</td>\n",
       "      <td>-1.76621</td>\n",
       "      <td>-0.039923</td>\n",
       "      <td>0.034056</td>\n",
       "      <td>-0.002113</td>\n",
       "      <td>9.886115</td>\n",
       "      <td>0.052518</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.41</td>\n",
       "      <td>0</td>\n",
       "      <td>0.388697</td>\n",
       "      <td>9.53572</td>\n",
       "      <td>-1.72410</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>-0.010498</td>\n",
       "      <td>-0.020684</td>\n",
       "      <td>9.698122</td>\n",
       "      <td>0.024382</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.42</td>\n",
       "      <td>0</td>\n",
       "      <td>0.315800</td>\n",
       "      <td>9.49908</td>\n",
       "      <td>-1.60914</td>\n",
       "      <td>-0.003822</td>\n",
       "      <td>-0.011217</td>\n",
       "      <td>-0.025975</td>\n",
       "      <td>9.639584</td>\n",
       "      <td>0.028550</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_step  activity_id     acc_x    acc_y    acc_z    gyro_x    gyro_y  \\\n",
       "0       8.38            0  0.238080  9.80003 -1.68896 -0.005065 -0.006781   \n",
       "1       8.39            0  0.319530  9.61282 -1.49328  0.013685  0.001486   \n",
       "2       8.40            0  0.235593  9.72421 -1.76621 -0.039923  0.034056   \n",
       "3       8.41            0  0.388697  9.53572 -1.72410  0.007513 -0.010498   \n",
       "4       8.42            0  0.315800  9.49908 -1.60914 -0.003822 -0.011217   \n",
       "\n",
       "     gyro_z  acc_norm  gyro_norm User  \n",
       "0 -0.005663  9.947354   0.010184  101  \n",
       "1 -0.041522  9.733360   0.043744  101  \n",
       "2 -0.002113  9.886115   0.052518  101  \n",
       "3 -0.020684  9.698122   0.024382  101  \n",
       "4 -0.025975  9.639584   0.028550  101  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine to one df\n",
    "for d in range(len(data_list)):\n",
    "  if d==0:\n",
    "    df = data_list[0]\n",
    "  else:\n",
    "    df = pd.concat([df, data_list[d]], axis=0, ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# normal_1 = scaler.fit_transform(pak)\n",
    "\n",
    "def normalize(df, cols): #list of columns\n",
    "    df_t=(df[cols]-df[cols].mean())/df[cols].std() #均值为0，方差为1的分布\n",
    "    df_norm = df.copy()\n",
    "    df_norm[cols] = df_t\n",
    "\n",
    "    return df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_step</th>\n",
       "      <th>activity_id</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gyro_x</th>\n",
       "      <th>gyro_y</th>\n",
       "      <th>gyro_z</th>\n",
       "      <th>acc_norm</th>\n",
       "      <th>gyro_norm</th>\n",
       "      <th>User</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.238080</td>\n",
       "      <td>9.80003</td>\n",
       "      <td>-1.68896</td>\n",
       "      <td>-0.005065</td>\n",
       "      <td>-0.006781</td>\n",
       "      <td>-0.005663</td>\n",
       "      <td>-0.063877</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.319530</td>\n",
       "      <td>9.61282</td>\n",
       "      <td>-1.49328</td>\n",
       "      <td>0.013685</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>-0.041522</td>\n",
       "      <td>-0.118105</td>\n",
       "      <td>-0.762927</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.235593</td>\n",
       "      <td>9.72421</td>\n",
       "      <td>-1.76621</td>\n",
       "      <td>-0.039923</td>\n",
       "      <td>0.034056</td>\n",
       "      <td>-0.002113</td>\n",
       "      <td>-0.079396</td>\n",
       "      <td>-0.748460</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.41</td>\n",
       "      <td>0</td>\n",
       "      <td>0.388697</td>\n",
       "      <td>9.53572</td>\n",
       "      <td>-1.72410</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>-0.010498</td>\n",
       "      <td>-0.020684</td>\n",
       "      <td>-0.127035</td>\n",
       "      <td>-0.794854</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.42</td>\n",
       "      <td>0</td>\n",
       "      <td>0.315800</td>\n",
       "      <td>9.49908</td>\n",
       "      <td>-1.60914</td>\n",
       "      <td>-0.003822</td>\n",
       "      <td>-0.011217</td>\n",
       "      <td>-0.025975</td>\n",
       "      <td>-0.141869</td>\n",
       "      <td>-0.787982</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_step  activity_id     acc_x    acc_y    acc_z    gyro_x    gyro_y  \\\n",
       "0       8.38            0  0.238080  9.80003 -1.68896 -0.005065 -0.006781   \n",
       "1       8.39            0  0.319530  9.61282 -1.49328  0.013685  0.001486   \n",
       "2       8.40            0  0.235593  9.72421 -1.76621 -0.039923  0.034056   \n",
       "3       8.41            0  0.388697  9.53572 -1.72410  0.007513 -0.010498   \n",
       "4       8.42            0  0.315800  9.49908 -1.60914 -0.003822 -0.011217   \n",
       "\n",
       "     gyro_z  acc_norm  gyro_norm User  \n",
       "0 -0.005663 -0.063877  -0.818267  101  \n",
       "1 -0.041522 -0.118105  -0.762927  101  \n",
       "2 -0.002113 -0.079396  -0.748460  101  \n",
       "3 -0.020684 -0.127035  -0.794854  101  \n",
       "4 -0.025975 -0.141869  -0.787982  101  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_norm = normalize(df, ['acc_norm', 'gyro_norm'])\n",
    "data_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(df, cols, sigma=0.1):\n",
    "    noise = np.random.normal(0, sigma, df[cols].shape)\n",
    "    new_signal = df[cols] + noise\n",
    "    df_noise = df.copy()\n",
    "    df_noise[cols] = new_signal\n",
    "\n",
    "    return df_noise\n",
    "\n",
    "def augment(df, cols, num_of_inst):\n",
    "    '''\n",
    "    df should be inserted normalized\n",
    "    num_of_inst = num of instances to create from each instance\n",
    "    '''\n",
    "    aug_df = df.copy()\n",
    "    for i in range(num_of_inst):\n",
    "        np.random.seed(i)\n",
    "        nois_data = add_noise(df, cols)\n",
    "        nois_data['User'] = nois_data['User'] + f'{i}'\n",
    "        aug_df= pd.concat([aug_df, nois_data], axis=0, ignore_index=True)\n",
    "\n",
    "    return aug_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aug = augment(data_norm, ['acc_norm', 'gyro_norm'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_step</th>\n",
       "      <th>activity_id</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gyro_x</th>\n",
       "      <th>gyro_y</th>\n",
       "      <th>gyro_z</th>\n",
       "      <th>acc_norm</th>\n",
       "      <th>gyro_norm</th>\n",
       "      <th>User</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.238080</td>\n",
       "      <td>9.80003</td>\n",
       "      <td>-1.68896</td>\n",
       "      <td>-0.005065</td>\n",
       "      <td>-0.006781</td>\n",
       "      <td>-0.005663</td>\n",
       "      <td>-0.063877</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.319530</td>\n",
       "      <td>9.61282</td>\n",
       "      <td>-1.49328</td>\n",
       "      <td>0.013685</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>-0.041522</td>\n",
       "      <td>-0.118105</td>\n",
       "      <td>-0.762927</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.235593</td>\n",
       "      <td>9.72421</td>\n",
       "      <td>-1.76621</td>\n",
       "      <td>-0.039923</td>\n",
       "      <td>0.034056</td>\n",
       "      <td>-0.002113</td>\n",
       "      <td>-0.079396</td>\n",
       "      <td>-0.748460</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.41</td>\n",
       "      <td>0</td>\n",
       "      <td>0.388697</td>\n",
       "      <td>9.53572</td>\n",
       "      <td>-1.72410</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>-0.010498</td>\n",
       "      <td>-0.020684</td>\n",
       "      <td>-0.127035</td>\n",
       "      <td>-0.794854</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.42</td>\n",
       "      <td>0</td>\n",
       "      <td>0.315800</td>\n",
       "      <td>9.49908</td>\n",
       "      <td>-1.60914</td>\n",
       "      <td>-0.003822</td>\n",
       "      <td>-0.011217</td>\n",
       "      <td>-0.025975</td>\n",
       "      <td>-0.141869</td>\n",
       "      <td>-0.787982</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_step  activity_id     acc_x    acc_y    acc_z    gyro_x    gyro_y  \\\n",
       "0       8.38            0  0.238080  9.80003 -1.68896 -0.005065 -0.006781   \n",
       "1       8.39            0  0.319530  9.61282 -1.49328  0.013685  0.001486   \n",
       "2       8.40            0  0.235593  9.72421 -1.76621 -0.039923  0.034056   \n",
       "3       8.41            0  0.388697  9.53572 -1.72410  0.007513 -0.010498   \n",
       "4       8.42            0  0.315800  9.49908 -1.60914 -0.003822 -0.011217   \n",
       "\n",
       "     gyro_z  acc_norm  gyro_norm User  \n",
       "0 -0.005663 -0.063877  -0.818267  101  \n",
       "1 -0.041522 -0.118105  -0.762927  101  \n",
       "2 -0.002113 -0.079396  -0.748460  101  \n",
       "3 -0.020684 -0.127035  -0.794854  101  \n",
       "4 -0.025975 -0.141869  -0.787982  101  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_aug.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7 12 13 16 17 24]\n",
      "['101' '1010']\n"
     ]
    }
   ],
   "source": [
    "initial_data = data_aug\n",
    "print(np.unique(initial_data['activity_id']))\n",
    "print(np.unique(initial_data['User']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>timstep</th>\n",
       "      <th>user</th>\n",
       "      <th>acc_spec</th>\n",
       "      <th>gyro_spec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [activity, timstep, user, acc_spec, gyro_spec]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_actions = np.unique(initial_data['activity_id'])\n",
    "unique_users = np.unique(initial_data['User'])\n",
    "dff = pd.DataFrame(columns=['activity','timstep', 'user','acc_spec','gyro_spec'])\n",
    "print(dff.shape)\n",
    "dff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7 12 13 16 17 24]\n"
     ]
    }
   ],
   "source": [
    "print(unique_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action:  1\n",
      "user:  101\n",
      "(27179, 11) 6\n"
     ]
    }
   ],
   "source": [
    "path = '/Users/momo/Desktop'\n",
    "for action in [1,2,3]:\n",
    "    print('action: ', action)\n",
    "    for user in ['101']:\n",
    "        print('user: ', user)\n",
    "        act_user_temp = initial_data[(initial_data['activity_id']==action) & (initial_data['User']==user)]\n",
    "        NFFT = 25\n",
    "        noverlap = int(0.25 * NFFT)\n",
    "        print(act_user_temp.shape, noverlap)\n",
    "    break\n",
    "\n",
    "        # fig = plt.figure(frameon=False)\n",
    "        # sr = 100\n",
    "        # timestep = 0\n",
    "        # for row in range(0, act_user_temp.shape[0], 150): # overlap of the data is 50%. not the hyperparameter of FFT.\n",
    "        #     timestep += 1\n",
    "        #     spec_acc, freqenciesFound_x, time, imageAxis_x = plt.specgram(act_user_temp['acc_norm'][row:row + 200], Fs=100, NFFT=NFFT, noverlap=noverlap, window=np.hamming(NFFT),cmap='viridis')\n",
    "        #     spec_gyro, freqenciesFound_x, time, imageAxis_x = plt.specgram(act_user_temp['gyro_norm'][row:row + 200], Fs=100, NFFT=NFFT, noverlap=noverlap, window=np.hamming(NFFT),cmap='viridis')\n",
    "        #     instance = pd.DataFrame({'activity':action, 'timstep':timestep, 'user':user, 'acc_spec':[spec_acc], 'gyro_spec':[spec_gyro]})\n",
    "        #     dff = dff.append(instance, ignore_index=True) # label, timestep, user, f*t (spectrogram), f*t (spectrogram)\n",
    "        # plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27179,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = act_user_temp['acc_norm']\n",
    "acc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f802487df70>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(acc[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,t,Zxx = stft(acc.values, fs=100, nperseg=25, noverlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 1089)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccc = abs(Zxx)\n",
    "ccc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc1d1304d00>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(abs(Zxx)[:,:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 20, 13)\n"
     ]
    }
   ],
   "source": [
    "x = ccc.T\n",
    "input = []\n",
    "for i in range(0,len(x),15):\n",
    "    if i+20 <= len(x):\n",
    "        input.append(x[i:i+20])\n",
    "    else:\n",
    "        break\n",
    "input = np.array(input)\n",
    "print(input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 filtering targeted activities and making the labels sequencials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['activity'].isin([1,2,3,4,5,6,7,12,13,16,17])]\n",
    "df['activity'].loc[(df['activity']==12)] = 8\n",
    "df['activity'].loc[(df['activity']==13)] = 9\n",
    "df['activity'].loc[(df['activity']==16)] = 10\n",
    "df['activity'].loc[(df['activity']==17)] = 0\n",
    "df[df['activity'] == 10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 =  df[df['activity']==0]\n",
    "df0_100 = df0.reset_index().iloc[:1000]\n",
    "\n",
    "df1 =  df[df['activity']==1]\n",
    "df1_100 = df1.reset_index().iloc[:1000]\n",
    "\n",
    "df2 =  df[df['activity']==2]\n",
    "df2_100 = df2.reset_index().iloc[:1000]\n",
    "\n",
    "df3 =  df[df['activity']==3]\n",
    "df3_100 = df3.reset_index().iloc[:1000]\n",
    "\n",
    "df4 =  df[df['activity']==4]\n",
    "df4_100 = df4.reset_index().iloc[:1000]\n",
    "\n",
    "df5 =  df[df['activity']==5]\n",
    "df5_100 = df5.reset_index().iloc[:1000]\n",
    "\n",
    "df6 =  df[df['activity']==6]\n",
    "df6_100 = df6.reset_index().iloc[:1000]\n",
    "\n",
    "df7 =  df[df['activity']==7]\n",
    "df7_100 = df7.reset_index().iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df0_100, df1_100, df2_100, df3_100,df4_100,df5_100,df6_100,df7_100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_df = pd.DataFrame(columns=['id', 'input_5_timesteps', 'label'])\n",
    "id = 0\n",
    "for user in unique_users:\n",
    "    for action in unique_actions:\n",
    "        ua_df = df[(df['user']==user) & (df['activity']==action)]\n",
    "        for t in range(0, ua_df.shape[0], 5):\n",
    "          vec_acc = ua_df.iloc[t:t+5]['acc_spec'].tolist()\n",
    "          vec_gyro = ua_df.iloc[t:t+5]['gyro_spec'].tolist()\n",
    "          vec_acc_gyro = [vec_acc] + [vec_gyro]\n",
    "          instance = pd.DataFrame({'id': id, 'input_5_timesteps': [vec_acc_gyro], 'label': action})\n",
    "          loader_df = loader_df.append(instance, ignore_index=True)\n",
    "          id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********* 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5x/3g67fwns0mb68s__c_3fk4wr0000gn/T/ipykernel_54772/607291761.py:8: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /Users/distiller/project/conda/conda-bld/pytorch_1639180852547/work/torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x_tensor = torch.FloatTensor(x[i])\n"
     ]
    }
   ],
   "source": [
    "x = loader_df['input_5_timesteps']\n",
    "id = []\n",
    "label = []\n",
    "tensor_input = []\n",
    "\n",
    "for i in range(len(x)):\n",
    "  try:\n",
    "    x_tensor = torch.FloatTensor(x[i])\n",
    "    # print(x_tensor.shape)\n",
    "    if x_tensor.shape == torch.Size([2, 5, 13, 10]):\n",
    "      tensor_input.append(x_tensor)\n",
    "      label.append(loader_df['label'][i])\n",
    "      id.append(loader_df['id'][i])\n",
    "\n",
    "  except:\n",
    "    print('*********',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAANrklEQVR4nO3df6zd9V3H8efLtmQoRIq9kAaYnQTnyCIFr5WILgw2BfwDSLZENKxZSIpxGJbsjxH+cCz+w5IxjFFZymioZrIQYYKTTRscIhk/vCyltHYTRMSypr0MJzCTmZa3f5xvl+Zyb8+3955zbj/t85GcnHO+53t63p8Snjn32+85N1WFJKk9P7HcA0iSFseAS1KjDLgkNcqAS1KjDLgkNWrlJF9szZo1tW7dukm+pCQ179lnn32tqqbmbp9owNetW8fMzMwkX1KSmpfkP+fb7iEUSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWrURD+JKR2r1t3yd8s9wrxevv23lnsEHcN8By5JjRoa8CTvSvJMkueS7Ery2W77bUleTbK9u1w1/nElSYf0OYTyI+CyqnorySrgiSRf7x67s6o+P77xJEkLGRrwGvzW47e6u6u6i78JWZKWWa9j4ElWJNkO7Ae2VdXT3UM3JdmRZEuS1Qs8d1OSmSQzs7Ozo5laktQv4FV1sKrWA2cDG5K8H7gLOBdYD+wF7ljguZurarqqpqem3vF95JKkRTqqs1Cq6gfAY8AVVbWvC/vbwN3AhtGPJ0laSJ+zUKaSnNbdPhn4EPCdJGsP2+1aYOdYJpQkzavPWShrga1JVjAI/v1V9bUkf5lkPYN/0HwZuHFsU0qS3qHPWSg7gAvn2X79WCaSJPXiJzElqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaNTTgSd6V5JkkzyXZleSz3fbTk2xL8kJ3vXr840qSDunzDvxHwGVVdQGwHrgiycXALcCjVXUe8Gh3X5I0IUMDXgNvdXdXdZcCrga2dtu3AteMY0BJ0vx6HQNPsiLJdmA/sK2qngbOrKq9AN31GQs8d1OSmSQzs7OzIxpbktQr4FV1sKrWA2cDG5K8v+8LVNXmqpququmpqalFjilJmuuozkKpqh8AjwFXAPuSrAXorvePejhJ0sL6nIUyleS07vbJwIeA7wAPAxu73TYCD41pRknSPFb22GctsDXJCgbBv7+qvpbkSeD+JDcArwAfHeOckqQ5hga8qnYAF86z/fvA5eMYSpI0nJ/ElKRGGXBJapQBl6RGGXBJapQBl6RGGXBJapQBl6RGGXBJapQBl6RGGXBJapQBl6RGGXBJapQBl6RGGXBJapQBl6RGGXBJapQBl6RGGXBJapQBl6RGGXBJatTQgCc5J8k3k+xOsivJzd3225K8mmR7d7lq/ONKkg4Z+lvpgQPAp6rq20lOBZ5Nsq177M6q+vz4xpMkLWRowKtqL7C3u/1mkt3AWeMeTJJ0ZEd1DDzJOuBC4Olu001JdiTZkmT1As/ZlGQmyczs7OzSppUk/VjvgCc5BXgA+GRVvQHcBZwLrGfwDv2O+Z5XVZurarqqpqemppY+sSQJ6BnwJKsYxPvLVfUgQFXtq6qDVfU2cDewYXxjSpLm6nMWSoB7gN1V9YXDtq89bLdrgZ2jH0+StJA+Z6FcAlwPPJ9ke7ftVuC6JOuBAl4GbhzDfJKkBfQ5C+UJIPM89Mjox5Ek9eUnMSWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckho1NOBJzknyzSS7k+xKcnO3/fQk25K80F2vHv+4kqRD+rwDPwB8qqreB1wMfCLJ+cAtwKNVdR7waHdfkjQhQwNeVXur6tvd7TeB3cBZwNXA1m63rcA1Y5pRkjSPozoGnmQdcCHwNHBmVe2FQeSBMxZ4zqYkM0lmZmdnlziuJOmQ3gFPcgrwAPDJqnqj7/OqanNVTVfV9NTU1GJmlCTNo1fAk6xiEO8vV9WD3eZ9SdZ2j68F9o9nREnSfPqchRLgHmB3VX3hsIceBjZ2tzcCD41+PEnSQlb22OcS4Hrg+STbu223ArcD9ye5AXgF+OhYJpQkzWtowKvqCSALPHz5aMeRJPXlJzElqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVF9fiv9liT7k+w8bNttSV5Nsr27XDXeMSVJc/V5B34vcMU82++sqvXd5ZHRjiVJGmZowKvqceD1CcwiSToKSzkGflOSHd0hltUjm0iS1MtiA34XcC6wHtgL3LHQjkk2JZlJMjM7O7vIl5MkzbWogFfVvqo6WFVvA3cDG46w7+aqmq6q6ampqcXOKUmaY1EBT7L2sLvXAjsX2leSNB4rh+2Q5D7gUmBNkj3AZ4BLk6wHCngZuHF8I0qS5jM04FV13Tyb7xnDLJKko+AnMSWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckho1NOBJtiTZn2TnYdtOT7ItyQvd9erxjilJmqvPO/B7gSvmbLsFeLSqzgMe7e5LkiZoaMCr6nHg9Tmbrwa2dre3AteMdixJ0jCLPQZ+ZlXtBeiuz1hoxySbkswkmZmdnV3ky0mS5hr7P2JW1eaqmq6q6ampqXG/nCSdMBYb8H1J1gJ01/tHN5IkqY/FBvxhYGN3eyPw0GjGkST11ec0wvuAJ4H3JtmT5AbgduDDSV4APtzdlyRN0MphO1TVdQs8dPmIZ5EkHQU/iSlJjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktSoob/U+EiSvAy8CRwEDlTV9CiGkiQNt6SAdz5YVa+N4M+RJB0FD6FIUqOWGvAC/iHJs0k2zbdDkk1JZpLMzM7OLvHlJEmHLDXgl1TVRcCVwCeSfGDuDlW1uaqmq2p6ampqiS8nSTpkSQGvqu911/uBrwIbRjGUJGm4RQc8yU8lOfXQbeA3gJ2jGkySdGRLOQvlTOCrSQ79OX9VVd8YyVSSpKEWHfCqegm4YISzSJKOgqcRSlKjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNWpJAU9yRZLvJnkxyS2jGkqSNNyiA55kBfBnwJXA+cB1Sc4f1WCSpCNbyjvwDcCLVfVSVf0f8BXg6tGMJUkaZuUSnnsW8F+H3d8D/MrcnZJsAjZ1d99K8t0lvOZyWQO8ttxDTNCJtl44Rtecz431jz8m1zxmra75Z+fbuJSAZ55t9Y4NVZuBzUt4nWWXZKaqppd7jkk50dYLrvlEcbyteSmHUPYA5xx2/2zge0sbR5LU11IC/i/AeUnek+Qk4LeBh0czliRpmEUfQqmqA0luAv4eWAFsqapdI5vs2NL0IaBFONHWC675RHFcrTlV7zhsLUlqgJ/ElKRGGXBJapQB7/T5WoAklybZnmRXkn+a9IyjNmzNSX46yd8mea5b88eXY85RSbIlyf4kOxd4PEn+pPv72JHkoknPOGo91vy73Vp3JPlWkgsmPeOoDVvzYfv9cpKDST4yqdlGrqpO+AuDf4T9d+DngJOA54Dz5+xzGvCvwLu7+2cs99wTWPOtwOe621PA68BJyz37Etb8AeAiYOcCj18FfJ3BZxwuBp5e7pknsOZfBVZ3t688Edbc7bMC+EfgEeAjyz3zYi++Ax/o87UAvwM8WFWvAFTV/gnPOGp91lzAqUkCnMIg4AcmO+boVNXjDNawkKuBv6iBp4DTkqydzHTjMWzNVfWtqvrv7u5TDD7P0bQe/50B/gB4AGj6/2MDPjDf1wKcNWefnwdWJ3ksybNJPjax6cajz5r/FHgfgw9oPQ/cXFVvT2a8ZdHn7+R4dgODn0COa0nOAq4FvrjcsyzVUj5Kfzzp87UAK4FfAi4HTgaeTPJUVf3buIcbkz5r/k1gO3AZcC6wLck/V9UbY55tufT6eojjUZIPMgj4ry33LBPwx8Cnq+rg4IfLdhnwgT5fC7AHeK2qfgj8MMnjwAVAqwHvs+aPA7fX4KDhi0n+A/gF4JnJjDhxJ+TXQyT5ReBLwJVV9f3lnmcCpoGvdPFeA1yV5EBV/c2yTrUIHkIZ6PO1AA8Bv55kZZKfZPDNi7snPOco9VnzKwx+4iDJmcB7gZcmOuVkPQx8rDsb5WLgf6pq73IPNU5J3g08CFzf8E+TR6Wq3lNV66pqHfDXwO+3GG/wHTiw8NcCJPm97vEvVtXuJN8AdgBvA1+qqiOepnQs67Nm4I+Ae5M8z+DwwqerqsWv4gQgyX3ApcCaJHuAzwCr4MfrfYTBmSgvAv/L4CeQpvVY8x8CPwP8efeO9EA1/m19PdZ83PCj9JLUKA+hSFKjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1Kj/h+hn05szexk2QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(label, bins=8);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 36, 36)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id), len(label), len(tensor_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1]), array([36]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(label, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([72, 1, 20, 13])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_input = torch.tensor(input)\n",
    "tensor_input = tensor_input.unsqueeze(1)\n",
    "tensor_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.zeros((72,6))\n",
    "label[0:72,0] = 1\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5x/3g67fwns0mb68s__c_3fk4wr0000gn/T/ipykernel_3434/855225357.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(label)\n"
     ]
    }
   ],
   "source": [
    "# id = torch.tensor(id)\n",
    "label = torch.tensor(label)\n",
    "# tensor_input = torch.stack((tensor_input,tensor_input),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([72, 1, 20, 13])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_input.shape # (num_of_instances, K:2, t:5, feature: 13,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 training samples\n",
      "15 validation samples\n"
     ]
    }
   ],
   "source": [
    "dataset = TensorDataset(tensor_input, label)\n",
    "train_size = int(0.80 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print(f'{train_size} training samples')\n",
    "print(f'{val_size} validation samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "batch_size = 5\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  \n",
    "            sampler = RandomSampler(train_dataset), \n",
    "            batch_size = batch_size\n",
    "            )\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, \n",
    "            sampler = SequentialSampler(val_dataset),\n",
    "            batch_size = batch_size\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 20, 13])\n",
      "torch.Size([5, 6])\n"
     ]
    }
   ],
   "source": [
    "for data in train_dataloader:\n",
    "    inputs, labels = data\n",
    "    print(inputs.shape)\n",
    "    print(labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 5, sharex=True, sharey=False, figsize=(15,5))\n",
    "instance = next(iter(train_dataloader))\n",
    "for i in range(5):\n",
    "    axes[0,i].imshow(instance[1][0][0][i])\n",
    "    axes[0,i].set_title(f'acc timestep {i+1}')\n",
    "for i in range(5):\n",
    "    axes[1,i].imshow(instance[1][0][1][i])\n",
    "    axes[1,i].set_title(f'gyro timestep {i+1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "data.shape: [B, K, T, F]\n",
    "====== train CNN for every mode ======\n",
    "conv_in.shape: [B, C, T, F]\n",
    "conv_out.shape:[B, T, D] D=C*F\n",
    "============ merge modes =============\n",
    "attn1_in.shape: [B, T, M, D] M:mode\n",
    "attn1_out.shape:[B, T, D]\n",
    "============ train GRU ===============\n",
    "gru_in.shape: [B, T, D]\n",
    "gru_out.shape:[B, T, D']\n",
    "=========== merge time info ==========\n",
    "attn2_in.shape: [B, T, D']\n",
    "attn2_out.shape:[B, D']\n",
    "fc_in.shape: [B, N] N: num_activities\n",
    "output.shape:[B, N]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv(nn.Module):\n",
    "    # input shape: Batch,in_channels,H(time),W(frequency)\n",
    "    # in this case: Batch, in_channels, time_window, frequency\n",
    "    def __init__(self, in_channels=1, CONV_C=CONV_C, CONV_K=CONV_K, padding='valid'):\n",
    "        super(Conv, self).__init__()\n",
    "        if padding == 'valid':\n",
    "            self.padding = 0\n",
    "        elif padding == 'same':\n",
    "            self.padding = 'same'\n",
    "        else:\n",
    "            raise ValueError(\"Invalid padding mode. Use 'valid' or 'same'.\")\n",
    "            \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, CONV_C[0], [1,CONV_K[0]], stride=(1, 2), padding=self.padding),\n",
    "            nn.BatchNorm2d(CONV_C[0]), \n",
    "            # Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=1-CONV_KEEP_PROB),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(CONV_C[0], CONV_C[1], [1,CONV_K[1]], stride=(1,1), padding=self.padding),\n",
    "            nn.BatchNorm2d(CONV_C[1]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=1-CONV_KEEP_PROB),\n",
    "            nn.MaxPool2d((1,3),stride=1, padding = (0,1))\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(CONV_C[1], CONV_C[2], [1,CONV_K[2]], stride=(1,1), padding=self.padding),\n",
    "            nn.BatchNorm2d(CONV_C[2]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d((1,3),stride=1, padding =(0,1))\n",
    "        )\n",
    "        # self.fc = nn.Linear(in_channels, CONV_C)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        print('x.shape 1: ', inputs.shape)\n",
    "        x = self.conv1(inputs)\n",
    "        print('x.shape 2: ', x.shape)\n",
    "        x = self.conv2(x)\n",
    "        print('x.shape 3: ', x.shape)\n",
    "        x = self.conv3(x)\n",
    "        print('x.shape 4: ', x.shape) #[B,C,T,f]\n",
    "        xx = x.transpose(1,2).contiguous() #[B,T,C,f]\n",
    "\n",
    "        xx = xx.unsqueeze(2) # shape = [B,T,1,C,f]\n",
    "        print('x.shape 5: ', xx.shape)\n",
    "        # x = torch.flatten(x, start_dim=1) # shape = [B,C*f*t]\n",
    "        # print('x.shape 5: ', x.shape)\n",
    "        # x = self.fc(x)\n",
    "        # print('x.shape 6: ', x.shape)\n",
    "        return xx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ATTEN_M(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ATTEN_M, self).__init__()\n",
    "        self.d = 128\n",
    "        self.w = torch.nn.Parameter(torch.randn(self.d, requires_grad=True) * 0.1) # weights\n",
    "        self.b = torch.nn.Parameter(torch.randn(1, requires_grad=True))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        activation = torch.tanh(torch.tensordot(inputs, self.w, dims=[[-1],[0]]) + self.b)  # b * t * m\n",
    "        print('activation:',activation.shape)\n",
    "        alphas = F.softmax(activation, dim=2)  # b * t * m\n",
    "        print(\"alphas:\", str(alphas.shape))\n",
    "        \n",
    "        beta = inputs * alphas.unsqueeze(-1)\n",
    "        print('beta:',beta.shape)\n",
    "        output = torch.sum(beta, dim=2)  # b * t * d = [b,t,i,d] * [b,t,i,1] element_wise\n",
    "        print('attn_m.shape:',output.shape) #shape: [batch, time_window, feature_dim]\n",
    "        return output, alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_mode(inputs): # Attention-fusion Subnet\n",
    "    \"\"\"\n",
    "    input shape: [batch, time_window, input_mode, feature_dim(f*channels)]\n",
    "    output shape:[batch, time_window, feature_dim]\n",
    "    \n",
    "    \"\"\"\n",
    "    d = inputs.shape[-1]\n",
    "\n",
    "    w = torch.nn.Parameter(torch.randn(d, requires_grad=True) * 0.1) # weights\n",
    "    b = torch.nn.Parameter(torch.randn(1, requires_grad=True))\n",
    "\n",
    "    activation = torch.tanh(torch.tensordot(inputs, w, dims=1) + b)  # b * t * m\n",
    "    alphas = F.softmax(activation, dim=2)  # b * t * m\n",
    "    print(\"alphas \", str(alphas.shape))\n",
    "\n",
    "    # l = inputs.shape[-2]\n",
    "    # print(d,l)\n",
    "    # w = torch.randn([d,l], requires_grad=True, dtype=torch.double) * 0.1 # weights\n",
    "    # b = torch.randn(l, requires_grad=True, dtype=torch.double) * 0.1 \n",
    "    # omega = torch.randn(l, requires_grad=True, dtype=torch.double) * 0.1 \n",
    "    # activation = torch.tanh(torch.matmul(inputs,w) + b)  # b * t * m * m = [b,t,i,d] * [d,i]\n",
    "    # activation = torch.matmul(activation,omega) # b * t * m = [b,t,i,i] * [i]\n",
    "    # alphas = F.softmax(activation, dim=2)  # b * t * m\n",
    "    # print(\"alphas \", str(alphas.shape))\n",
    "    \n",
    "    beta = inputs * alphas.unsqueeze(-1)\n",
    "    print(beta.shape)\n",
    "    output = torch.sum(beta, dim=2)  # b * t * d = [b,t,i,d] * [b,t,i,1] element_wise\n",
    "    print(output.shape) #shape: [batch, time_window, feature_dim]\n",
    "    return output, alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ATTEN_T(nn.Module):\n",
    "    def __init__(self, d = GRU_H[-1], attention_size=AT):\n",
    "        super(ATTEN_T, self).__init__()\n",
    "        self.d = d\n",
    "        self.w_omega = nn.Parameter(torch.randn(self.d, attention_size) * 0.1)\n",
    "        self.b_omega = nn.Parameter(torch.randn(attention_size) * 0.1)\n",
    "        self.u_omega = nn.Parameter(torch.randn(attention_size) * 0.1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v = torch.tanh(torch.matmul(inputs, self.w_omega) + self.b_omega)  # (B,T,A) shape\n",
    "        # For each of the timestamps, its vector of size A from `v` is reduced with the `u` vector\n",
    "        vu = torch.matmul(v, self.u_omega).squeeze(-1)  # (B,T) shape\n",
    "        alphas = F.softmax(vu, dim=1)   # (B,T) shape\n",
    "\n",
    "        # Output of (Bi-)RNN is reduced with the attention vector; the result has (B,D) shape\n",
    "        output = torch.sum(inputs * alphas.unsqueeze(-1), dim=1)\n",
    "\n",
    "        return output, alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_time(inputs, attention_size):\n",
    "    \"\"\"\n",
    "    input shape: [batch, time_window, feature_dim]\n",
    "    output shape:[batch, feature_dim]\n",
    "    \"\"\"\n",
    "    if isinstance(inputs, tuple):\n",
    "        # In case of Bi-RNN, concatenate the forward and the backward RNN outputs.\n",
    "        inputs = torch.cat(inputs, 2)\n",
    "    \n",
    "    hidden_size = inputs.shape[2]  #inputs: (B,T,D)\n",
    "\n",
    "    # Trainable parameters\n",
    "    w_omega = nn.Parameter(torch.randn(hidden_size, attention_size) * 0.1)\n",
    "    b_omega = nn.Parameter(torch.randn(attention_size) * 0.1)\n",
    "    u_omega = nn.Parameter(torch.randn(attention_size) * 0.1)\n",
    "    # with torch.name_scope('v'):\n",
    "    #     # Applying fully connected layer with non-linear activation to each of the B*T timestamps;\n",
    "    #     # the shape of `v` is (B,T,D)*(D,A)=(B,T,A), where A=attention_size\n",
    "    #     v = torch.tanh(torch.matmul(inputs, w_omega) + b_omega)\n",
    "\n",
    "    v = torch.tanh(torch.matmul(inputs, w_omega) + b_omega)  # (B,T,A) shape\n",
    "    # For each of the timestamps, its vector of size A from `v` is reduced with the `u` vector\n",
    "    vu = torch.matmul(v, u_omega).squeeze(-1)  # (B,T) shape\n",
    "    alphas = F.softmax(vu, dim=1)   # (B,T) shape\n",
    "\n",
    "    # Output of (Bi-)RNN is reduced with the attention vector; the result has (B,D) shape\n",
    "    output = torch.sum(inputs * alphas.unsqueeze(-1), dim=1)\n",
    "\n",
    "    return output, alphas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 AttnSense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnSense(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AttnSense, self).__init__()\n",
    "        self.conv = Conv()\n",
    "        # self.attn1 = attention_mode()\n",
    "        # self.attn2 = attention_time()\n",
    "        self.attn1 = ATTEN_M()\n",
    "        self.attn2 = ATTEN_T()\n",
    "\n",
    "        # Define GRU layer\n",
    "        # nn.GRU(input_size, hidden_size, num_layers)\n",
    "        # input:[batch, seq_len, input_size], h_0:[num_layers * num_directions, batch, hidden_size], defaults to zeros if not provided.\n",
    "        # output: [batch, seq_len, hidden_size * num_directions], containing the output features (h_t) from the last layer of the GRU, for each t.\n",
    "        # h_n:[num_layers * num_directions, batch, hidden_size], containing the final hidden state for the input sequence.\n",
    "        self.g_input_size = CONV_C[2]*2\n",
    "        self.gru1 = nn.GRU(self.g_input_size, GRU_H[0], batch_first=True)\n",
    "        self.gru2 = nn.GRU(GRU_H[0], GRU_H[1], batch_first=True)\n",
    "        self.fc_gru = nn.Linear(GRU_H[1],6) # input: [B,D]\n",
    "\n",
    "    def forward(self, inputs, modes):\n",
    "        # split data based on modality and train Conv for every modality.\n",
    "        # m = []\n",
    "        # for i in range(modes):\n",
    "        #     m.append(inputs[0][i].reshape(BATCH_SIZE,1,WIDE,13))\n",
    "\n",
    "        # conv_out_1 = self.conv(m[0])\n",
    "        # conv_out_2 = self.conv(m[1])\n",
    "        # conv_out_all = torch.cat([conv_out_1, conv_out_2], dim=2) # [B,T,M,C,f]\n",
    "        conv_out_1 = self.conv(inputs)\n",
    "        conv_out_2 = self.conv(inputs)\n",
    "        conv_out_all = torch.cat([conv_out_1, conv_out_2], dim=2) # [B,T,M,C,f]\n",
    "        print('conv_out_all.shape:',conv_out_all.shape)\n",
    "        # print('conv_out.shape:', conv_out_1.shape, conv_out_2.shape, conv_out_all.shape)\n",
    "\n",
    "        attn1_in = conv_out_all.view(conv_out_all.size(0), conv_out_all.size(1), conv_out_all.size(2),\n",
    "                                            conv_out_all.size(3) * conv_out_all.size(4))\n",
    "        print('attn1_in.shape:', attn1_in.shape) #[B,T,M,D]\n",
    "        attn1_out, _ = self.attn1(attn1_in) # out: [B,T,D]\n",
    "\n",
    "        # self.init_state = torch.zeros(2, attn1_out.size(0), self.cell.hidden_size, dtype=torch.float32)\n",
    "        # h_t = self.init_state\n",
    "        # for t in range(attn1_out.size(1)):\n",
    "        #     h_t = self.cell(attn1_out[:, t], h_t)\n",
    "        #     gru_out.append(h_t)\n",
    "        # gru_out = torch.stack(gru_out, dim=1)  # (batch, time_window, DIM)\n",
    "\n",
    "        gru_1, _ = self.gru1(attn1_out)\n",
    "        gru_out, _ = self.gru2(gru_1)\n",
    "        print('gru_out.shape:', gru_out.shape) # [B,T,D']\n",
    "\n",
    "        # attn2_out, _ = self.attn2(gru_out, attention_size=AT) \n",
    "        attn2_out, _ = self.attn2(gru_out) \n",
    "        print('attn2_out.shape:', attn2_out.shape) # [B,D']\n",
    "        \n",
    "        x = self.fc_gru(attn2_out)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        print(x,x.shape)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,  \n",
    "    sampler = RandomSampler(train_dataset), \n",
    "    batch_size = BATCH_SIZE\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    sampler = SequentialSampler(val_dataset),\n",
    "    batch_size = BATCH_SIZE\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    sampler = SequentialSampler(test_dataset),\n",
    "    batch_size = BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, traindata, valdata, epochs, path, num, lr=0.001):\n",
    "    model = model.to(device).float()\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(), lr)#.to(device)\n",
    "\n",
    "    # low_loss = 0\n",
    "    history = dict(train=[], val=[])\n",
    "    t_s = time.time()\n",
    "\n",
    "    for epoch in range(1,epochs+1):\n",
    "        t_ss = time.time()\n",
    "        model = model.train()\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        print(epoch, \"start!\")\n",
    "        for data in traindata:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device).float()\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs,modes=None)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        train_loss = np.mean(train_losses)\n",
    "        history['train'].append(train_loss)\n",
    "        \n",
    "        if epoch % 50 == 49:\n",
    "            model = model.eval()\n",
    "            with torch.no_grad():\n",
    "                for data in valdata:\n",
    "                    inputs, labels = data\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    outputs = model(inputs,modes=None)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    val_losses.append(loss.item())\n",
    "\n",
    "            val_loss = np.mean(val_losses)\n",
    "            history['val'].append(val_loss)\n",
    "            print(f'Epoch = {epoch}, val loss = {val_loss}')\n",
    "\n",
    "        t_ee = time.time()\n",
    "        print(f'Epoch = {epoch}, train loss = {train_loss}, time = {t_ee-t_ss}')\n",
    "\n",
    "        # if val_loss < 1.7 and low_loss == 0:\n",
    "        #     low_loss = val_loss\n",
    "        #     torch.save(model.state_dict(), path+'Attn_model'+num)\n",
    "        # if val_loss < low_loss:\n",
    "        #     low_loss = val_loss\n",
    "        #     torch.save(model.state_dict(), path+'Attn_model'+num)\n",
    "\n",
    "    t_e = time.time()\n",
    "    print(f'Finish! time_cost: {t_e-t_s}')\n",
    "\n",
    "    return model.eval(), history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 start!\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "conv_out_all.shape: torch.Size([5, 20, 2, 64, 2])\n",
      "attn1_in.shape: torch.Size([5, 20, 2, 128])\n",
      "activation: torch.Size([5, 20, 2])\n",
      "alphas: torch.Size([5, 20, 2])\n",
      "beta: torch.Size([5, 20, 2, 128])\n",
      "attn_m.shape: torch.Size([5, 20, 128])\n",
      "gru_out.shape: torch.Size([5, 20, 120])\n",
      "attn2_out.shape: torch.Size([5, 120])\n",
      "tensor([[0.1989, 0.1782, 0.1426, 0.1706, 0.1416, 0.1682],\n",
      "        [0.1702, 0.1973, 0.1612, 0.1737, 0.1466, 0.1511],\n",
      "        [0.1874, 0.1895, 0.1569, 0.1762, 0.1299, 0.1601],\n",
      "        [0.1945, 0.1780, 0.1511, 0.1874, 0.1424, 0.1466],\n",
      "        [0.1715, 0.1859, 0.1581, 0.1858, 0.1486, 0.1501]],\n",
      "       grad_fn=<SoftmaxBackward0>) torch.Size([5, 6])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "conv_out_all.shape: torch.Size([5, 20, 2, 64, 2])\n",
      "attn1_in.shape: torch.Size([5, 20, 2, 128])\n",
      "activation: torch.Size([5, 20, 2])\n",
      "alphas: torch.Size([5, 20, 2])\n",
      "beta: torch.Size([5, 20, 2, 128])\n",
      "attn_m.shape: torch.Size([5, 20, 128])\n",
      "gru_out.shape: torch.Size([5, 20, 120])\n",
      "attn2_out.shape: torch.Size([5, 120])\n",
      "tensor([[0.2546, 0.1650, 0.1500, 0.1680, 0.1227, 0.1398],\n",
      "        [0.2331, 0.1775, 0.1488, 0.1581, 0.1406, 0.1419],\n",
      "        [0.2959, 0.1528, 0.1344, 0.1567, 0.1160, 0.1441],\n",
      "        [0.2578, 0.1763, 0.1415, 0.1703, 0.1177, 0.1364],\n",
      "        [0.2453, 0.1718, 0.1440, 0.1592, 0.1334, 0.1464]],\n",
      "       grad_fn=<SoftmaxBackward0>) torch.Size([5, 6])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "conv_out_all.shape: torch.Size([5, 20, 2, 64, 2])\n",
      "attn1_in.shape: torch.Size([5, 20, 2, 128])\n",
      "activation: torch.Size([5, 20, 2])\n",
      "alphas: torch.Size([5, 20, 2])\n",
      "beta: torch.Size([5, 20, 2, 128])\n",
      "attn_m.shape: torch.Size([5, 20, 128])\n",
      "gru_out.shape: torch.Size([5, 20, 120])\n",
      "attn2_out.shape: torch.Size([5, 120])\n",
      "tensor([[0.3249, 0.1530, 0.1222, 0.1548, 0.1077, 0.1373],\n",
      "        [0.3526, 0.1397, 0.1254, 0.1413, 0.1120, 0.1289],\n",
      "        [0.3585, 0.1410, 0.1195, 0.1555, 0.0973, 0.1282],\n",
      "        [0.3780, 0.1518, 0.1280, 0.1335, 0.1002, 0.1086],\n",
      "        [0.3611, 0.1523, 0.1214, 0.1264, 0.1093, 0.1296]],\n",
      "       grad_fn=<SoftmaxBackward0>) torch.Size([5, 6])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "conv_out_all.shape: torch.Size([5, 20, 2, 64, 2])\n",
      "attn1_in.shape: torch.Size([5, 20, 2, 128])\n",
      "activation: torch.Size([5, 20, 2])\n",
      "alphas: torch.Size([5, 20, 2])\n",
      "beta: torch.Size([5, 20, 2, 128])\n",
      "attn_m.shape: torch.Size([5, 20, 128])\n",
      "gru_out.shape: torch.Size([5, 20, 120])\n",
      "attn2_out.shape: torch.Size([5, 120])\n",
      "tensor([[0.3998, 0.1321, 0.1204, 0.1245, 0.1007, 0.1224],\n",
      "        [0.4540, 0.1190, 0.1089, 0.1193, 0.0930, 0.1058],\n",
      "        [0.4657, 0.1231, 0.1057, 0.1133, 0.0882, 0.1039],\n",
      "        [0.3583, 0.1507, 0.1287, 0.1288, 0.1102, 0.1233],\n",
      "        [0.3708, 0.1519, 0.1271, 0.1323, 0.1063, 0.1115]],\n",
      "       grad_fn=<SoftmaxBackward0>) torch.Size([5, 6])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "conv_out_all.shape: torch.Size([5, 20, 2, 64, 2])\n",
      "attn1_in.shape: torch.Size([5, 20, 2, 128])\n",
      "activation: torch.Size([5, 20, 2])\n",
      "alphas: torch.Size([5, 20, 2])\n",
      "beta: torch.Size([5, 20, 2, 128])\n",
      "attn_m.shape: torch.Size([5, 20, 128])\n",
      "gru_out.shape: torch.Size([5, 20, 120])\n",
      "attn2_out.shape: torch.Size([5, 120])\n",
      "tensor([[0.6194, 0.0885, 0.0781, 0.0808, 0.0594, 0.0738],\n",
      "        [0.5678, 0.0961, 0.0953, 0.0897, 0.0699, 0.0813],\n",
      "        [0.5770, 0.0972, 0.0873, 0.0923, 0.0652, 0.0811],\n",
      "        [0.5958, 0.0897, 0.0832, 0.0856, 0.0638, 0.0818],\n",
      "        [0.5594, 0.0979, 0.0929, 0.0966, 0.0709, 0.0822]],\n",
      "       grad_fn=<SoftmaxBackward0>) torch.Size([5, 6])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "conv_out_all.shape: torch.Size([5, 20, 2, 64, 2])\n",
      "attn1_in.shape: torch.Size([5, 20, 2, 128])\n",
      "activation: torch.Size([5, 20, 2])\n",
      "alphas: torch.Size([5, 20, 2])\n",
      "beta: torch.Size([5, 20, 2, 128])\n",
      "attn_m.shape: torch.Size([5, 20, 128])\n",
      "gru_out.shape: torch.Size([5, 20, 120])\n",
      "attn2_out.shape: torch.Size([5, 120])\n",
      "tensor([[0.5509, 0.0994, 0.0953, 0.0916, 0.0718, 0.0910],\n",
      "        [0.7229, 0.0620, 0.0594, 0.0567, 0.0452, 0.0538],\n",
      "        [0.6797, 0.0710, 0.0675, 0.0673, 0.0505, 0.0639],\n",
      "        [0.6413, 0.0794, 0.0783, 0.0763, 0.0565, 0.0682],\n",
      "        [0.6294, 0.0873, 0.0779, 0.0732, 0.0604, 0.0717]],\n",
      "       grad_fn=<SoftmaxBackward0>) torch.Size([5, 6])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "conv_out_all.shape: torch.Size([5, 20, 2, 64, 2])\n",
      "attn1_in.shape: torch.Size([5, 20, 2, 128])\n",
      "activation: torch.Size([5, 20, 2])\n",
      "alphas: torch.Size([5, 20, 2])\n",
      "beta: torch.Size([5, 20, 2, 128])\n",
      "attn_m.shape: torch.Size([5, 20, 128])\n",
      "gru_out.shape: torch.Size([5, 20, 120])\n",
      "attn2_out.shape: torch.Size([5, 120])\n",
      "tensor([[0.7959, 0.0449, 0.0458, 0.0402, 0.0334, 0.0399],\n",
      "        [0.7456, 0.0586, 0.0572, 0.0544, 0.0378, 0.0465],\n",
      "        [0.7976, 0.0438, 0.0444, 0.0420, 0.0323, 0.0400],\n",
      "        [0.8208, 0.0381, 0.0414, 0.0350, 0.0294, 0.0353],\n",
      "        [0.7744, 0.0517, 0.0511, 0.0463, 0.0333, 0.0431]],\n",
      "       grad_fn=<SoftmaxBackward0>) torch.Size([5, 6])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "conv_out_all.shape: torch.Size([5, 20, 2, 64, 2])\n",
      "attn1_in.shape: torch.Size([5, 20, 2, 128])\n",
      "activation: torch.Size([5, 20, 2])\n",
      "alphas: torch.Size([5, 20, 2])\n",
      "beta: torch.Size([5, 20, 2, 128])\n",
      "attn_m.shape: torch.Size([5, 20, 128])\n",
      "gru_out.shape: torch.Size([5, 20, 120])\n",
      "attn2_out.shape: torch.Size([5, 120])\n",
      "tensor([[0.8745, 0.0272, 0.0290, 0.0240, 0.0195, 0.0258],\n",
      "        [0.8758, 0.0272, 0.0289, 0.0251, 0.0189, 0.0242],\n",
      "        [0.8608, 0.0303, 0.0347, 0.0257, 0.0218, 0.0268],\n",
      "        [0.8495, 0.0328, 0.0350, 0.0293, 0.0233, 0.0301],\n",
      "        [0.8813, 0.0249, 0.0270, 0.0235, 0.0177, 0.0256]],\n",
      "       grad_fn=<SoftmaxBackward0>) torch.Size([5, 6])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "conv_out_all.shape: torch.Size([5, 20, 2, 64, 2])\n",
      "attn1_in.shape: torch.Size([5, 20, 2, 128])\n",
      "activation: torch.Size([5, 20, 2])\n",
      "alphas: torch.Size([5, 20, 2])\n",
      "beta: torch.Size([5, 20, 2, 128])\n",
      "attn_m.shape: torch.Size([5, 20, 128])\n",
      "gru_out.shape: torch.Size([5, 20, 120])\n",
      "attn2_out.shape: torch.Size([5, 120])\n",
      "tensor([[0.9030, 0.0207, 0.0238, 0.0185, 0.0150, 0.0191],\n",
      "        [0.8798, 0.0263, 0.0286, 0.0217, 0.0195, 0.0243],\n",
      "        [0.8911, 0.0237, 0.0269, 0.0208, 0.0167, 0.0208],\n",
      "        [0.8989, 0.0207, 0.0244, 0.0196, 0.0159, 0.0205],\n",
      "        [0.9091, 0.0183, 0.0215, 0.0174, 0.0139, 0.0198]],\n",
      "       grad_fn=<SoftmaxBackward0>) torch.Size([5, 6])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "conv_out_all.shape: torch.Size([5, 20, 2, 64, 2])\n",
      "attn1_in.shape: torch.Size([5, 20, 2, 128])\n",
      "activation: torch.Size([5, 20, 2])\n",
      "alphas: torch.Size([5, 20, 2])\n",
      "beta: torch.Size([5, 20, 2, 128])\n",
      "attn_m.shape: torch.Size([5, 20, 128])\n",
      "gru_out.shape: torch.Size([5, 20, 120])\n",
      "attn2_out.shape: torch.Size([5, 120])\n",
      "tensor([[0.9216, 0.0163, 0.0195, 0.0139, 0.0124, 0.0163],\n",
      "        [0.9124, 0.0180, 0.0218, 0.0161, 0.0137, 0.0181],\n",
      "        [0.8445, 0.0357, 0.0357, 0.0288, 0.0243, 0.0310],\n",
      "        [0.9078, 0.0191, 0.0226, 0.0165, 0.0150, 0.0190],\n",
      "        [0.8546, 0.0317, 0.0350, 0.0268, 0.0230, 0.0289]],\n",
      "       grad_fn=<SoftmaxBackward0>) torch.Size([5, 6])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "conv_out_all.shape: torch.Size([5, 20, 2, 64, 2])\n",
      "attn1_in.shape: torch.Size([5, 20, 2, 128])\n",
      "activation: torch.Size([5, 20, 2])\n",
      "alphas: torch.Size([5, 20, 2])\n",
      "beta: torch.Size([5, 20, 2, 128])\n",
      "attn_m.shape: torch.Size([5, 20, 128])\n",
      "gru_out.shape: torch.Size([5, 20, 120])\n",
      "attn2_out.shape: torch.Size([5, 120])\n",
      "tensor([[0.9458, 0.0108, 0.0134, 0.0098, 0.0085, 0.0116],\n",
      "        [0.9374, 0.0132, 0.0160, 0.0110, 0.0095, 0.0129],\n",
      "        [0.9423, 0.0115, 0.0148, 0.0101, 0.0090, 0.0123],\n",
      "        [0.9298, 0.0148, 0.0174, 0.0123, 0.0109, 0.0147],\n",
      "        [0.9227, 0.0152, 0.0197, 0.0137, 0.0121, 0.0166]],\n",
      "       grad_fn=<SoftmaxBackward0>) torch.Size([5, 6])\n",
      "x.shape 1:  torch.Size([2, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([2, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([2, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([2, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([2, 20, 1, 64, 2])\n",
      "x.shape 1:  torch.Size([2, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([2, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([2, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([2, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([2, 20, 1, 64, 2])\n",
      "conv_out_all.shape: torch.Size([2, 20, 2, 64, 2])\n",
      "attn1_in.shape: torch.Size([2, 20, 2, 128])\n",
      "activation: torch.Size([2, 20, 2])\n",
      "alphas: torch.Size([2, 20, 2])\n",
      "beta: torch.Size([2, 20, 2, 128])\n",
      "attn_m.shape: torch.Size([2, 20, 128])\n",
      "gru_out.shape: torch.Size([2, 20, 120])\n",
      "attn2_out.shape: torch.Size([2, 120])\n",
      "tensor([[0.9538, 0.0094, 0.0121, 0.0080, 0.0071, 0.0097],\n",
      "        [0.9488, 0.0100, 0.0130, 0.0087, 0.0083, 0.0112]],\n",
      "       grad_fn=<SoftmaxBackward0>) torch.Size([2, 6])\n",
      "Epoch = 1, train loss = 1.3477393895387648, time = 0.29984307289123535\n",
      "2 start!\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "conv_out_all.shape: torch.Size([5, 20, 2, 64, 2])\n",
      "attn1_in.shape: torch.Size([5, 20, 2, 128])\n",
      "activation: torch.Size([5, 20, 2])\n",
      "alphas: torch.Size([5, 20, 2])\n",
      "beta: torch.Size([5, 20, 2, 128])\n",
      "attn_m.shape: torch.Size([5, 20, 128])\n",
      "gru_out.shape: torch.Size([5, 20, 120])\n",
      "attn2_out.shape: torch.Size([5, 120])\n",
      "tensor([[0.9538, 0.0094, 0.0116, 0.0079, 0.0073, 0.0100],\n",
      "        [0.9474, 0.0105, 0.0133, 0.0090, 0.0085, 0.0114],\n",
      "        [0.9341, 0.0132, 0.0170, 0.0114, 0.0105, 0.0138],\n",
      "        [0.9537, 0.0091, 0.0123, 0.0078, 0.0074, 0.0096],\n",
      "        [0.9469, 0.0110, 0.0131, 0.0097, 0.0079, 0.0115]],\n",
      "       grad_fn=<SoftmaxBackward0>) torch.Size([5, 6])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "conv_out_all.shape: torch.Size([5, 20, 2, 64, 2])\n",
      "attn1_in.shape: torch.Size([5, 20, 2, 128])\n",
      "activation: torch.Size([5, 20, 2])\n",
      "alphas: torch.Size([5, 20, 2])\n",
      "beta: torch.Size([5, 20, 2, 128])\n",
      "attn_m.shape: torch.Size([5, 20, 128])\n",
      "gru_out.shape: torch.Size([5, 20, 120])\n",
      "attn2_out.shape: torch.Size([5, 120])\n",
      "tensor([[0.9591, 0.0082, 0.0106, 0.0067, 0.0067, 0.0087],\n",
      "        [0.9566, 0.0083, 0.0110, 0.0076, 0.0068, 0.0098],\n",
      "        [0.9483, 0.0104, 0.0133, 0.0087, 0.0084, 0.0109],\n",
      "        [0.9653, 0.0070, 0.0090, 0.0058, 0.0054, 0.0075],\n",
      "        [0.9523, 0.0094, 0.0126, 0.0081, 0.0076, 0.0100]],\n",
      "       grad_fn=<SoftmaxBackward0>) torch.Size([5, 6])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "conv_out_all.shape: torch.Size([5, 20, 2, 64, 2])\n",
      "attn1_in.shape: torch.Size([5, 20, 2, 128])\n",
      "activation: torch.Size([5, 20, 2])\n",
      "alphas: torch.Size([5, 20, 2])\n",
      "beta: torch.Size([5, 20, 2, 128])\n",
      "attn_m.shape: torch.Size([5, 20, 128])\n",
      "gru_out.shape: torch.Size([5, 20, 120])\n",
      "attn2_out.shape: torch.Size([5, 120])\n",
      "tensor([[0.9307, 0.0143, 0.0174, 0.0118, 0.0115, 0.0145],\n",
      "        [0.9586, 0.0083, 0.0109, 0.0070, 0.0063, 0.0089],\n",
      "        [0.9592, 0.0084, 0.0106, 0.0069, 0.0063, 0.0086],\n",
      "        [0.9585, 0.0083, 0.0104, 0.0071, 0.0067, 0.0090],\n",
      "        [0.9485, 0.0105, 0.0131, 0.0084, 0.0084, 0.0111]],\n",
      "       grad_fn=<SoftmaxBackward0>) torch.Size([5, 6])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "conv_out_all.shape: torch.Size([5, 20, 2, 64, 2])\n",
      "attn1_in.shape: torch.Size([5, 20, 2, 128])\n",
      "activation: torch.Size([5, 20, 2])\n",
      "alphas: torch.Size([5, 20, 2])\n",
      "beta: torch.Size([5, 20, 2, 128])\n",
      "attn_m.shape: torch.Size([5, 20, 128])\n",
      "gru_out.shape: torch.Size([5, 20, 120])\n",
      "attn2_out.shape: torch.Size([5, 120])\n",
      "tensor([[0.9690, 0.0059, 0.0081, 0.0051, 0.0049, 0.0069],\n",
      "        [0.9678, 0.0061, 0.0085, 0.0053, 0.0053, 0.0071],\n",
      "        [0.9527, 0.0092, 0.0124, 0.0077, 0.0075, 0.0105],\n",
      "        [0.9683, 0.0064, 0.0082, 0.0051, 0.0051, 0.0068],\n",
      "        [0.9672, 0.0066, 0.0083, 0.0055, 0.0053, 0.0071]],\n",
      "       grad_fn=<SoftmaxBackward0>) torch.Size([5, 6])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "conv_out_all.shape: torch.Size([5, 20, 2, 64, 2])\n",
      "attn1_in.shape: torch.Size([5, 20, 2, 128])\n",
      "activation: torch.Size([5, 20, 2])\n",
      "alphas: torch.Size([5, 20, 2])\n",
      "beta: torch.Size([5, 20, 2, 128])\n",
      "attn_m.shape: torch.Size([5, 20, 128])\n",
      "gru_out.shape: torch.Size([5, 20, 120])\n",
      "attn2_out.shape: torch.Size([5, 120])\n",
      "tensor([[0.9662, 0.0067, 0.0087, 0.0056, 0.0054, 0.0073],\n",
      "        [0.9640, 0.0071, 0.0094, 0.0059, 0.0057, 0.0079],\n",
      "        [0.9466, 0.0112, 0.0135, 0.0089, 0.0085, 0.0112],\n",
      "        [0.9652, 0.0068, 0.0089, 0.0058, 0.0056, 0.0076],\n",
      "        [0.9559, 0.0090, 0.0116, 0.0070, 0.0070, 0.0096]],\n",
      "       grad_fn=<SoftmaxBackward0>) torch.Size([5, 6])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "conv_out_all.shape: torch.Size([5, 20, 2, 64, 2])\n",
      "attn1_in.shape: torch.Size([5, 20, 2, 128])\n",
      "activation: torch.Size([5, 20, 2])\n",
      "alphas: torch.Size([5, 20, 2])\n",
      "beta: torch.Size([5, 20, 2, 128])\n",
      "attn_m.shape: torch.Size([5, 20, 128])\n",
      "gru_out.shape: torch.Size([5, 20, 120])\n",
      "attn2_out.shape: torch.Size([5, 120])\n",
      "tensor([[0.9437, 0.0114, 0.0140, 0.0094, 0.0092, 0.0123],\n",
      "        [0.9580, 0.0087, 0.0107, 0.0070, 0.0065, 0.0091],\n",
      "        [0.9738, 0.0051, 0.0071, 0.0042, 0.0042, 0.0057],\n",
      "        [0.9628, 0.0073, 0.0097, 0.0059, 0.0062, 0.0082],\n",
      "        [0.9558, 0.0090, 0.0111, 0.0075, 0.0073, 0.0094]],\n",
      "       grad_fn=<SoftmaxBackward0>) torch.Size([5, 6])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "conv_out_all.shape: torch.Size([5, 20, 2, 64, 2])\n",
      "attn1_in.shape: torch.Size([5, 20, 2, 128])\n",
      "activation: torch.Size([5, 20, 2])\n",
      "alphas: torch.Size([5, 20, 2])\n",
      "beta: torch.Size([5, 20, 2, 128])\n",
      "attn_m.shape: torch.Size([5, 20, 128])\n",
      "gru_out.shape: torch.Size([5, 20, 120])\n",
      "attn2_out.shape: torch.Size([5, 120])\n",
      "tensor([[0.9729, 0.0052, 0.0070, 0.0044, 0.0044, 0.0061],\n",
      "        [0.9716, 0.0056, 0.0077, 0.0045, 0.0045, 0.0060],\n",
      "        [0.9747, 0.0048, 0.0068, 0.0041, 0.0041, 0.0055],\n",
      "        [0.9696, 0.0061, 0.0079, 0.0047, 0.0048, 0.0069],\n",
      "        [0.9775, 0.0043, 0.0059, 0.0036, 0.0037, 0.0050]],\n",
      "       grad_fn=<SoftmaxBackward0>) torch.Size([5, 6])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "conv_out_all.shape: torch.Size([5, 20, 2, 64, 2])\n",
      "attn1_in.shape: torch.Size([5, 20, 2, 128])\n",
      "activation: torch.Size([5, 20, 2])\n",
      "alphas: torch.Size([5, 20, 2])\n",
      "beta: torch.Size([5, 20, 2, 128])\n",
      "attn_m.shape: torch.Size([5, 20, 128])\n",
      "gru_out.shape: torch.Size([5, 20, 120])\n",
      "attn2_out.shape: torch.Size([5, 120])\n",
      "tensor([[0.9748, 0.0047, 0.0066, 0.0040, 0.0042, 0.0057],\n",
      "        [0.9740, 0.0050, 0.0070, 0.0040, 0.0044, 0.0056],\n",
      "        [0.9748, 0.0048, 0.0069, 0.0039, 0.0041, 0.0056],\n",
      "        [0.9797, 0.0040, 0.0054, 0.0032, 0.0032, 0.0045],\n",
      "        [0.9756, 0.0048, 0.0065, 0.0038, 0.0040, 0.0053]],\n",
      "       grad_fn=<SoftmaxBackward0>) torch.Size([5, 6])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "conv_out_all.shape: torch.Size([5, 20, 2, 64, 2])\n",
      "attn1_in.shape: torch.Size([5, 20, 2, 128])\n",
      "activation: torch.Size([5, 20, 2])\n",
      "alphas: torch.Size([5, 20, 2])\n",
      "beta: torch.Size([5, 20, 2, 128])\n",
      "attn_m.shape: torch.Size([5, 20, 128])\n",
      "gru_out.shape: torch.Size([5, 20, 120])\n",
      "attn2_out.shape: torch.Size([5, 120])\n",
      "tensor([[0.9762, 0.0048, 0.0062, 0.0039, 0.0037, 0.0053],\n",
      "        [0.9776, 0.0041, 0.0060, 0.0036, 0.0039, 0.0049],\n",
      "        [0.9756, 0.0048, 0.0066, 0.0038, 0.0038, 0.0055],\n",
      "        [0.9821, 0.0033, 0.0048, 0.0027, 0.0031, 0.0040],\n",
      "        [0.9744, 0.0052, 0.0068, 0.0041, 0.0039, 0.0057]],\n",
      "       grad_fn=<SoftmaxBackward0>) torch.Size([5, 6])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "conv_out_all.shape: torch.Size([5, 20, 2, 64, 2])\n",
      "attn1_in.shape: torch.Size([5, 20, 2, 128])\n",
      "activation: torch.Size([5, 20, 2])\n",
      "alphas: torch.Size([5, 20, 2])\n",
      "beta: torch.Size([5, 20, 2, 128])\n",
      "attn_m.shape: torch.Size([5, 20, 128])\n",
      "gru_out.shape: torch.Size([5, 20, 120])\n",
      "attn2_out.shape: torch.Size([5, 120])\n",
      "tensor([[0.9774, 0.0044, 0.0060, 0.0036, 0.0036, 0.0050],\n",
      "        [0.9725, 0.0053, 0.0072, 0.0044, 0.0045, 0.0060],\n",
      "        [0.9709, 0.0060, 0.0075, 0.0047, 0.0046, 0.0064],\n",
      "        [0.9724, 0.0055, 0.0073, 0.0043, 0.0044, 0.0062],\n",
      "        [0.9742, 0.0051, 0.0068, 0.0041, 0.0042, 0.0057]],\n",
      "       grad_fn=<SoftmaxBackward0>) torch.Size([5, 6])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "conv_out_all.shape: torch.Size([5, 20, 2, 64, 2])\n",
      "attn1_in.shape: torch.Size([5, 20, 2, 128])\n",
      "activation: torch.Size([5, 20, 2])\n",
      "alphas: torch.Size([5, 20, 2])\n",
      "beta: torch.Size([5, 20, 2, 128])\n",
      "attn_m.shape: torch.Size([5, 20, 128])\n",
      "gru_out.shape: torch.Size([5, 20, 120])\n",
      "attn2_out.shape: torch.Size([5, 120])\n",
      "tensor([[0.9796, 0.0040, 0.0055, 0.0032, 0.0032, 0.0045],\n",
      "        [0.9789, 0.0040, 0.0057, 0.0033, 0.0034, 0.0046],\n",
      "        [0.9839, 0.0031, 0.0043, 0.0025, 0.0026, 0.0036],\n",
      "        [0.9798, 0.0038, 0.0053, 0.0031, 0.0033, 0.0046],\n",
      "        [0.9744, 0.0050, 0.0068, 0.0040, 0.0042, 0.0057]],\n",
      "       grad_fn=<SoftmaxBackward0>) torch.Size([5, 6])\n",
      "x.shape 1:  torch.Size([2, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([2, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([2, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([2, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([2, 20, 1, 64, 2])\n",
      "x.shape 1:  torch.Size([2, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([2, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([2, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([2, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([2, 20, 1, 64, 2])\n",
      "conv_out_all.shape: torch.Size([2, 20, 2, 64, 2])\n",
      "attn1_in.shape: torch.Size([2, 20, 2, 128])\n",
      "activation: torch.Size([2, 20, 2])\n",
      "alphas: torch.Size([2, 20, 2])\n",
      "beta: torch.Size([2, 20, 2, 128])\n",
      "attn_m.shape: torch.Size([2, 20, 128])\n",
      "gru_out.shape: torch.Size([2, 20, 120])\n",
      "attn2_out.shape: torch.Size([2, 120])\n",
      "tensor([[0.9797, 0.0040, 0.0054, 0.0032, 0.0033, 0.0045],\n",
      "        [0.9828, 0.0033, 0.0046, 0.0026, 0.0028, 0.0039]],\n",
      "       grad_fn=<SoftmaxBackward0>) torch.Size([2, 6])\n",
      "Epoch = 2, train loss = 1.0698275397221246, time = 0.2511022090911865\n",
      "Finish! time_cost: 0.5510830879211426\n"
     ]
    }
   ],
   "source": [
    "model = AttnSense()\n",
    "# model, history = train_model(model, train_loader, val_loader, EPOCH,path,num=1)\n",
    "model, history = train_model(model, train_dataloader, train_dataloader, 2, PATH,num=1,lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fc1d12b39d0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['train'],label='train loss')\n",
    "# plt.plot(history['val'], label='val loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" save model \"\"\"\n",
    "model_1 = model\n",
    "MODEL_PATH = 'Attn_model_final.pth'\n",
    "torch.save(model_1, MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method AttnSense.forward of AttnSense(\n",
      "  (conv): Conv(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv2d(1, 32, kernel_size=(1, 3), stride=(1, 2))\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Dropout2d(p=0.19999999999999996, inplace=False)\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): Conv2d(32, 32, kernel_size=(1, 3), stride=(1, 1))\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Dropout2d(p=0.19999999999999996, inplace=False)\n",
      "      (4): MaxPool2d(kernel_size=(1, 3), stride=1, padding=(0, 1), dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (conv3): Sequential(\n",
      "      (0): Conv2d(32, 64, kernel_size=(1, 3), stride=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): MaxPool2d(kernel_size=(1, 3), stride=1, padding=(0, 1), dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (attn1): ATTEN_M()\n",
      "  (attn2): ATTEN_T()\n",
      "  (gru1): GRU(128, 120, batch_first=True)\n",
      "  (gru2): GRU(120, 120, batch_first=True)\n",
      "  (fc_gru): Linear(in_features=120, out_features=6, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "model_2 = torch.load(\"Attn_model_final.pth\")\n",
    "print(model_2.forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_model(model, testdata):\n",
    "    model = model.eval().float()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = torch.tensor([])\n",
    "    all_lab = torch.tensor([])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in testdata:\n",
    "            inputs, labels = data\n",
    "            outputs = model(inputs.float(), modes=None) # [B, n_classes]\n",
    "\n",
    "            true = torch.argmax(labels, 1) # [B]\n",
    "            predict = torch.argmax(outputs.data, 1) # [B]\n",
    "            total += labels.size(0)\n",
    "            correct += (predict == true).sum().item()\n",
    "\n",
    "            all_preds = torch.cat((all_preds, predict) ,dim=0)\n",
    "            all_lab = torch.cat((all_lab, true) ,dim=0)\n",
    "    print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n",
    "    print('all_preds.shape: ', all_preds.shape, 'all_labels.shape: ', all_lab.shape)\n",
    "    return all_lab, all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "conv_out_all.shape: torch.Size([5, 20, 2, 64, 2])\n",
      "attn1_in.shape: torch.Size([5, 20, 2, 128])\n",
      "activation: torch.Size([5, 20, 2])\n",
      "alphas: torch.Size([5, 20, 2])\n",
      "beta: torch.Size([5, 20, 2, 128])\n",
      "attn_m.shape: torch.Size([5, 20, 128])\n",
      "gru_out.shape: torch.Size([5, 20, 120])\n",
      "attn2_out.shape: torch.Size([5, 120])\n",
      "tensor([[0.9712, 0.0057, 0.0078, 0.0044, 0.0047, 0.0062],\n",
      "        [0.9719, 0.0056, 0.0076, 0.0043, 0.0046, 0.0060],\n",
      "        [0.9711, 0.0057, 0.0078, 0.0044, 0.0047, 0.0062],\n",
      "        [0.9710, 0.0057, 0.0078, 0.0044, 0.0047, 0.0062],\n",
      "        [0.9714, 0.0057, 0.0077, 0.0044, 0.0047, 0.0062]]) torch.Size([5, 6])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "conv_out_all.shape: torch.Size([5, 20, 2, 64, 2])\n",
      "attn1_in.shape: torch.Size([5, 20, 2, 128])\n",
      "activation: torch.Size([5, 20, 2])\n",
      "alphas: torch.Size([5, 20, 2])\n",
      "beta: torch.Size([5, 20, 2, 128])\n",
      "attn_m.shape: torch.Size([5, 20, 128])\n",
      "gru_out.shape: torch.Size([5, 20, 120])\n",
      "attn2_out.shape: torch.Size([5, 120])\n",
      "tensor([[0.9718, 0.0056, 0.0076, 0.0043, 0.0046, 0.0061],\n",
      "        [0.9709, 0.0057, 0.0079, 0.0045, 0.0048, 0.0062],\n",
      "        [0.9710, 0.0057, 0.0079, 0.0045, 0.0047, 0.0062],\n",
      "        [0.9713, 0.0057, 0.0078, 0.0044, 0.0047, 0.0062],\n",
      "        [0.9709, 0.0057, 0.0079, 0.0045, 0.0048, 0.0062]]) torch.Size([5, 6])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "x.shape 1:  torch.Size([5, 1, 20, 13])\n",
      "x.shape 2:  torch.Size([5, 32, 20, 6])\n",
      "x.shape 3:  torch.Size([5, 32, 20, 4])\n",
      "x.shape 4:  torch.Size([5, 64, 20, 2])\n",
      "x.shape 5:  torch.Size([5, 20, 1, 64, 2])\n",
      "conv_out_all.shape: torch.Size([5, 20, 2, 64, 2])\n",
      "attn1_in.shape: torch.Size([5, 20, 2, 128])\n",
      "activation: torch.Size([5, 20, 2])\n",
      "alphas: torch.Size([5, 20, 2])\n",
      "beta: torch.Size([5, 20, 2, 128])\n",
      "attn_m.shape: torch.Size([5, 20, 128])\n",
      "gru_out.shape: torch.Size([5, 20, 120])\n",
      "attn2_out.shape: torch.Size([5, 120])\n",
      "tensor([[0.9711, 0.0057, 0.0078, 0.0044, 0.0047, 0.0062],\n",
      "        [0.9708, 0.0058, 0.0079, 0.0045, 0.0048, 0.0063],\n",
      "        [0.9710, 0.0057, 0.0079, 0.0044, 0.0047, 0.0062],\n",
      "        [0.9710, 0.0058, 0.0079, 0.0044, 0.0047, 0.0062],\n",
      "        [0.9719, 0.0056, 0.0076, 0.0043, 0.0046, 0.0061]]) torch.Size([5, 6])\n",
      "Accuracy of the network on the test images: 100 %\n",
      "all_preds.shape:  torch.Size([15]) all_labels.shape:  torch.Size([15])\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = evaluation_model(model, validation_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true, y_pred, labels=activities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAAD8CAYAAABAWd66AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAPxklEQVR4nO3df6zddX3H8eerMLJJ2MLWlVnKQnXAggb5AzsNMQEj2HWLaLY/qDHTSVI1qdk0xrGYDSMxcU7lH4zxil1DFtqwRAxxHchmsmaJk1YD0iLMpla53M1rh8Mf24B7z3t/3NN5dnvuPefeHXo/99vng3xyz/dzPt/P93OT5s277+/n+22qCknS2tuw1guQJC0wIEtSIwzIktQIA7IkNcKALEmNMCBLUiMMyJK0hCR7kswmObKo/71JnkxyNMnHlzj3RJLHkjyS5PA41zt3EouWpI7aC9wJ3H2qI8n1wE3AVVX1XJJNy5x/fVWdHPdiZsiStISqOgg8s6j7PcDHquq5/pjZSV3vRc+QD295s48CShrLNdNfzP93jhdOHh875pz3qy9/F7BroGuqqqZGnHY58LokHwX+G/hAVR0aMq6ALycp4LNjzGvJQlLH9ObHHtoPkiMD5SLnAhcCrwFeDdyb5GV1+nsorq2qmX5J46EkT/Qz7iVZspDULdUbv63ONPCFWvAw0AM2nraMqpn+z1ngPmDbqIkNyJK6pdcbv63OF4HXAyS5HDgP+D837pKcn+SCU5+BG4EjjGDJQlKn1Ooz39Mk2QdcB2xMMg3cBuwB9vS3wj0PvL2qKslm4K6q2gFcBNyXBBbi7D1V9cCo6xmQJXXL/NzEpqqqnUt89bYhY2eAHf3Px4FXrfR6BmRJ3bKCm3qtMSBL6pYJlizONAOypG5Z/c26NWdAltQpk7ypd6YZkCV1ixmyJDVi/oW1XsGqGZAldYslC0lqhCULSWqEGbIkNcIMWZLaUD1v6klSG8yQJakR1pAlqRG+XEiSGmGGLEmNsIYsSY2Y4AvqzzQDsqRuMUOWpDZUeVNPktpghixJjXCXhSQ1wgxZkhrhLgtJaoQlC0lqhCULSWqEAVmSGrGOSxYb1noBkjRR83PjtxGS7Ekym+TIov73JnkyydEkH1/i3O39MceS3DrO0s2QJXXLZEsWe4E7gbtPdSS5HrgJuKqqnkuyafFJSc4BPg3cAEwDh5LcX1WPL3cxM2RJ3VK98duoqaoOAs8s6n4P8LGqeq4/ZnbIqduAY1V1vKqeB/azEMSXZUCW1C293vhtdS4HXpfka0n+Mcmrh4y5GHhq4Hi637csSxaSumUFgTbJLmDXQNdUVU2NOO1c4ELgNcCrgXuTvKyqanDqIefVkL7TJpak7qiRcW9gaE0BowLwYtPAF/oB+OEkPWAj8INFYy4ZON4CzIya2JKFpG6Zmxu/rc4XgdcDJLkcOA84uWjMIeCyJFuTnAfcDNw/amIDsqRumeBNvST7gK8CVySZTnILsAd4WX8r3H7g7VVVSTYnOQBQVXPAbuBB4FvAvVV1dNT1LFlI6pYJbnurqp1LfPW2IWNngB0DxweAAyu5ngFZUresoIbcGgOypG7xXRaS1AgDsiS1oeb9R04lqQ1myJLUiHX8+k0DsqRu6bnLQpLaYMlCkhrhTT1JaoQZsiQ1whqyJDXCXRaS1AgzZElqQ1lDlqRGuMtCkhphyUKSGmHJQpIaYYYsSY1w25skNcIMWZLaUHPuspCkNpghS1IjrCFLUiPMkCWpDWVAlqRGeFNPkhphhixJjVjHAXnDWi9AkiapqsZuoyTZk2Q2yZGBvg8neTrJI/22Y4lzTyR5rD/m8DhrN0OW1C2TzZD3AncCdy/qv6OqPjHG+ddX1clxL2ZAltQtEwzIVXUwyaUTm3AESxaSOqXmemO3JLuSHB5ou8a8zO4k3+yXNC5cainAl5N8fdx5zZAldcsKHtSrqilgaoVX+AxwOwsB93bgk8A7h4y7tqpmkmwCHkryRFUdXG5iM2RJnVK9Grutav6q71fVfFX1gM8B25YYN9P/OQvct9S4QQZkSd3Sq/HbKiR56cDhW4AjQ8acn+SCU5+BG4eNW8yShaRumeC7hZLsA64DNiaZBm4DrktyNQslixPAu/pjNwN3VdUO4CLgviSwEGfvqaoHRl3PgCypUyb5Louq2jmk+/NLjJ0BdvQ/HwdetdLrGZAldUrNrd8n9QzIkrpl/b4O2YAsqVvW8fvpDciSOsaALEltMEOWpEbU3FqvYPUMyJI6xQxZkhphQJakVlTWegWrZkCW1ClmyJLUiOqZIUtSE3rzBmRJaoIlC0lqhCULSWpErd+XvRmQJXWLGbIkNcKbepLUCDNkSWpE+aSeJLXBbW+S1IieGbIktcGShSQ1wl0WktQId1lIUiOsIUtSI6whS8u49BO7+aU3XMPcyWc5+oY/AmDz+29m41tvYO7ffwTA03/x1zz7la+v5TLVEev5XRYb1noB6r6Tf/MVvv22j5zW//3P3c/jb3wfj7/xfQZjTUyvMnYbJcmeJLNJjgz0fTjJ00ke6bcdS5y7PcmTSY4luXWctRuQ9aL7ydceZ+4/frLWy9BZotfL2G0Me4HtQ/rvqKqr++3A4i+TnAN8Gvht4EpgZ5IrR11sZMkiyW8CNwEXAwXMAPdX1bdGnSstZ9M7fodf+f3r+c9Hj/HU7X/F/LM/XeslqQMmeVOvqg4muXQVp24DjlXVcYAk+1mIo48vd9KyGXKSPwH2AwEeBg71P+9bLgVPsivJ4SSHv/DTEyv5JXSWmL3773js2nfz+I3v44XZH3LJn/3hWi9JHVGVsdtgrOq3XWNeZneSb/ZLGhcO+f5i4KmB4+l+37JGZci3AK+oqhcGO5N8CjgKfGzYSVU1BUwBHN7y5nVcYteLZe7ks//7+Qf3PMRlez+0hqtRl6wkQx6MVSvwGeB2FioGtwOfBN65aMywRYyMhaNqyD1g85D+l/a/k1bl5zb9LKm4cPtv8V9Pfm8NV6MuqRW0Vc1f9f2qmq+qHvA5FsoTi00Dlwwcb2Gh3LusURnyHwP/kOTb/Cz9/nXgN4DdoyaXALbe+X4ueO0rOfeXf5GrDt3FzCf3c8FrX8kvvGIrVPH8U7N899bPrPUy1RHzvRd3r0KSl1bVv/YP3wIcGTLsEHBZkq3A08DNwFtHzb1sQK6qB5JczsL/AS5mIQ2fBg5V1fz4v4LOZt/Z/anT+k7u//s1WInOBpP8q3uSfcB1wMYk08BtwHVJrmYhyT4BvKs/djNwV1XtqKq5JLuBB4FzgD1VdXTU9Ubusuin5f+8qt9Gks6wGlq+XeVcVTuHdH9+ibEzwI6B4wPAaVviluOTepI6pbeOtxEYkCV1Sm+CGfKZZkCW1CmTLFmcaQZkSZ0yb0CWpDas5wckDMiSOsWALEmNsIYsSY1Yx/+kngFZUre47U2SGrGe3+lgQJbUKb2YIUtSE9bxk9MGZEnd4rY3SWqEuywkqRE+Oi1JjTBDlqRGWEOWpEa4y0KSGmHJQpIaYclCkhoxb4YsSW0wQ5akRhiQJakR7rKQpEa4y0KSGmHJQpIasZ5fUL9hrRcgSZPUy/htlCR7kswmOTLkuw8kqSQblzj3RJLHkjyS5PA4azcgS+qU3graGPYC2xd3JrkEuAH43ojzr6+qq6vqmnEuZkCW1Cm1gjZyrqqDwDNDvroD+OCY04zNgCypU3rU2C3JriSHB9quUfMneRPwdFU9OmJoAV9O8vVx5gVv6knqmJXc1KuqKWBq3PFJXgJ8CLhxjOHXVtVMkk3AQ0me6GfcSzJDltQpE64hL/ZyYCvwaJITwBbgG0l+bfHAqprp/5wF7gO2jZrcDFlSp7yYD4ZU1WPAplPH/aB8TVWdHByX5HxgQ1X9uP/5RuAjo+Y3Q5bUKSupIY+SZB/wVeCKJNNJbllm7OYkB/qHFwH/lORR4GHgb6vqgVHXM0OW1CmT3PZQVTtHfH/pwOcZYEf/83HgVSu9ngFZUqf46LQkNWJ+Hb/vzYAsqVPMkCWpEePcrGuVAVlSp6zfcGxAltQxliwkqRHe1JOkRlhDlqRGrN9wbECW1DFmyJLUCG/qSVIjygxZktrgLgtJaoQlC0lqRK/MkCWpCes3HBuQJXWM294kqRHuspCkRswZkCWpDWbIktQIt71JUiPKbW+S1AZ3WUhSI3x0WpIaYYYsSY2whixJjVjPuyw2rPUCJGmSagX/jZJkT5LZJEeGfPeBJJVk4xLnbk/yZJJjSW4dZ+0GZEmd0qPGbmPYC2xf3JnkEuAG4HvDTkpyDvBp4LeBK4GdSa4cdTEDsqROma/e2G2UqjoIPDPkqzuAD7L0y+W2Aceq6nhVPQ/sB24adT0DsqROmWTJYpgkbwKerqpHlxl2MfDUwPF0v29Z3tST1CkreUF9kl3AroGuqaqaWmb8S4APATeOmnpI38iFGZAldcpK8t5+8F0yAA/xcmAr8GgSgC3AN5Jsq6p/Gxg3DVwycLwFmBk1uQFZUqe8mA+GVNVjwKZTx0lOANdU1clFQw8BlyXZCjwN3Ay8ddT81pAldcokd1kk2Qd8FbgiyXSSW5YZuznJAYCqmgN2Aw8C3wLuraqjo65nhiypU8bZPTGuqto54vtLBz7PADsGjg8AB1ZyPQOypE7xBfWS1AjfZSFJjfBtb5LUCDNkSWrE/Dp+35sBWVKnrORJvdYYkCV1irssJKkRZsiS1AgzZElqhBmyJDViko9On2kGZEmdYslCkhpRZsiS1AYfnZakRvjotCQ1wgxZkhox37OGLElNcJeFJDXCGrIkNcIasiQ1wgxZkhrhTT1JaoQlC0lqhCULSWqEr9+UpEa4D1mSGmGGLEmN6Pn6TUlqwyRv6iXZA/wuMFtVr+z33Q7cBPSAWeAdVTUz5NwTwI+BeWCuqq4Zdb0NE1u5JDWgqsZuY9gLbF/U95dVdVVVXQ18CfjzZc6/vqquHicYgwFZUsfUCtrIuaoOAs8s6vvRwOH5Y041lqznPXtav5LsqqqptV6Hzm5JdgG7BrqmFv+5THIp8KVTJYt+30eBPwCeZSEL/sGQub8D/JCFgP3Zcf68G5C1JpIcHvevcdJaGhaQB777U+Dnq+q2Id9trqqZJJuAh4D39jPuJVmykKTVuwf4vWFfnLrRV1WzwH3AtlGTGZAlaQWSXDZw+CbgiSFjzk9ywanPwI3AkVFzu+1Na8X6sZqXZB9wHbAxyTRwG7AjyRUsbHv7LvDu/tjNwF1VtQO4CLgvCSzE2Xuq6oGR17OGLEltsGQhSY0wIEtSIwzIOuOSbE/yZJJjSW5d6/VIrbCGrDMqyTnAvwA3ANPAIWBnVT2+pguTGmCGrDNtG3Csqo5X1fPAfhZe1CKd9QzIOtMuBp4aOJ7u90lnPQOyzrQM6bNuJmFA1pk3DVwycLwFOO1dstLZyICsM+0QcFmSrUnOA24G7l/jNUlN8NFpnVFVNZdkN/AgcA6wp6qOrvGypCa47U2SGmHJQpIaYUCWpEYYkCWpEQZkSWqEAVmSGmFAlqRGGJAlqRH/A3ZVbIFhp8vCAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(pd.DataFrame(confusion_matrix(y_true, y_pred), columns=activities, index=activities), annot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
